{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "85e3b564",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/mnt/disk2/ndubrovnyi/words_similarity/.venv/lib/python3.8/site-packages/tqdm/auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "3878it [00:00, 2875289.18it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train size: 14342\n",
      "Val size: 3878\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "from transformers import BertTokenizer, BertForSequenceClassification, BertModel, AutoTokenizer, AutoModel\n",
    "from tqdm import tqdm\n",
    "\n",
    "from dataset import NamesDataset\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained('bert-base-uncased')\n",
    "\n",
    "train_dict_path = 'data/train_dict.json'\n",
    "val_dict_path = 'data/val_dict.json'\n",
    "\n",
    "trainset = NamesDataset(train_dict_path, tokenizer=tokenizer, max_length=32)\n",
    "valset = NamesDataset(val_dict_path, tokenizer=tokenizer, max_length=32)\n",
    "\n",
    "\n",
    "trainset_labels = set(trainset.labels)\n",
    "other_class_idx = 'other'\n",
    "for idx, label in tqdm(enumerate(valset.labels)):\n",
    "    if label not in trainset_labels:\n",
    "        valset.labels[idx] = other_class_idx\n",
    "valset.labels2target = trainset.labels2target\n",
    "    \n",
    "\n",
    "print('Train size:', len(trainset))\n",
    "print('Val size:', len(valset))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ae136b87",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertModel: ['cls.seq_relationship.weight', 'cls.seq_relationship.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.decoder.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.LayerNorm.bias']\n",
      "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "feature_extractor.embeddings.word_embeddings.weight False\n",
      "feature_extractor.embeddings.position_embeddings.weight False\n",
      "feature_extractor.embeddings.token_type_embeddings.weight False\n",
      "feature_extractor.embeddings.LayerNorm.weight False\n",
      "feature_extractor.embeddings.LayerNorm.bias False\n",
      "feature_extractor.encoder.layer.0.attention.self.query.weight False\n",
      "feature_extractor.encoder.layer.0.attention.self.query.bias False\n",
      "feature_extractor.encoder.layer.0.attention.self.key.weight False\n",
      "feature_extractor.encoder.layer.0.attention.self.key.bias False\n",
      "feature_extractor.encoder.layer.0.attention.self.value.weight False\n",
      "feature_extractor.encoder.layer.0.attention.self.value.bias False\n",
      "feature_extractor.encoder.layer.0.attention.output.dense.weight False\n",
      "feature_extractor.encoder.layer.0.attention.output.dense.bias False\n",
      "feature_extractor.encoder.layer.0.attention.output.LayerNorm.weight False\n",
      "feature_extractor.encoder.layer.0.attention.output.LayerNorm.bias False\n",
      "feature_extractor.encoder.layer.0.intermediate.dense.weight False\n",
      "feature_extractor.encoder.layer.0.intermediate.dense.bias False\n",
      "feature_extractor.encoder.layer.0.output.dense.weight False\n",
      "feature_extractor.encoder.layer.0.output.dense.bias False\n",
      "feature_extractor.encoder.layer.0.output.LayerNorm.weight False\n",
      "feature_extractor.encoder.layer.0.output.LayerNorm.bias False\n",
      "feature_extractor.encoder.layer.1.attention.self.query.weight False\n",
      "feature_extractor.encoder.layer.1.attention.self.query.bias False\n",
      "feature_extractor.encoder.layer.1.attention.self.key.weight False\n",
      "feature_extractor.encoder.layer.1.attention.self.key.bias False\n",
      "feature_extractor.encoder.layer.1.attention.self.value.weight False\n",
      "feature_extractor.encoder.layer.1.attention.self.value.bias False\n",
      "feature_extractor.encoder.layer.1.attention.output.dense.weight False\n",
      "feature_extractor.encoder.layer.1.attention.output.dense.bias False\n",
      "feature_extractor.encoder.layer.1.attention.output.LayerNorm.weight False\n",
      "feature_extractor.encoder.layer.1.attention.output.LayerNorm.bias False\n",
      "feature_extractor.encoder.layer.1.intermediate.dense.weight False\n",
      "feature_extractor.encoder.layer.1.intermediate.dense.bias False\n",
      "feature_extractor.encoder.layer.1.output.dense.weight False\n",
      "feature_extractor.encoder.layer.1.output.dense.bias False\n",
      "feature_extractor.encoder.layer.1.output.LayerNorm.weight False\n",
      "feature_extractor.encoder.layer.1.output.LayerNorm.bias False\n",
      "feature_extractor.encoder.layer.2.attention.self.query.weight False\n",
      "feature_extractor.encoder.layer.2.attention.self.query.bias False\n",
      "feature_extractor.encoder.layer.2.attention.self.key.weight False\n",
      "feature_extractor.encoder.layer.2.attention.self.key.bias False\n",
      "feature_extractor.encoder.layer.2.attention.self.value.weight False\n",
      "feature_extractor.encoder.layer.2.attention.self.value.bias False\n",
      "feature_extractor.encoder.layer.2.attention.output.dense.weight False\n",
      "feature_extractor.encoder.layer.2.attention.output.dense.bias False\n",
      "feature_extractor.encoder.layer.2.attention.output.LayerNorm.weight False\n",
      "feature_extractor.encoder.layer.2.attention.output.LayerNorm.bias False\n",
      "feature_extractor.encoder.layer.2.intermediate.dense.weight False\n",
      "feature_extractor.encoder.layer.2.intermediate.dense.bias False\n",
      "feature_extractor.encoder.layer.2.output.dense.weight False\n",
      "feature_extractor.encoder.layer.2.output.dense.bias False\n",
      "feature_extractor.encoder.layer.2.output.LayerNorm.weight False\n",
      "feature_extractor.encoder.layer.2.output.LayerNorm.bias False\n",
      "feature_extractor.encoder.layer.3.attention.self.query.weight False\n",
      "feature_extractor.encoder.layer.3.attention.self.query.bias False\n",
      "feature_extractor.encoder.layer.3.attention.self.key.weight False\n",
      "feature_extractor.encoder.layer.3.attention.self.key.bias False\n",
      "feature_extractor.encoder.layer.3.attention.self.value.weight False\n",
      "feature_extractor.encoder.layer.3.attention.self.value.bias False\n",
      "feature_extractor.encoder.layer.3.attention.output.dense.weight False\n",
      "feature_extractor.encoder.layer.3.attention.output.dense.bias False\n",
      "feature_extractor.encoder.layer.3.attention.output.LayerNorm.weight False\n",
      "feature_extractor.encoder.layer.3.attention.output.LayerNorm.bias False\n",
      "feature_extractor.encoder.layer.3.intermediate.dense.weight False\n",
      "feature_extractor.encoder.layer.3.intermediate.dense.bias False\n",
      "feature_extractor.encoder.layer.3.output.dense.weight False\n",
      "feature_extractor.encoder.layer.3.output.dense.bias False\n",
      "feature_extractor.encoder.layer.3.output.LayerNorm.weight False\n",
      "feature_extractor.encoder.layer.3.output.LayerNorm.bias False\n",
      "feature_extractor.encoder.layer.4.attention.self.query.weight False\n",
      "feature_extractor.encoder.layer.4.attention.self.query.bias False\n",
      "feature_extractor.encoder.layer.4.attention.self.key.weight False\n",
      "feature_extractor.encoder.layer.4.attention.self.key.bias False\n",
      "feature_extractor.encoder.layer.4.attention.self.value.weight False\n",
      "feature_extractor.encoder.layer.4.attention.self.value.bias False\n",
      "feature_extractor.encoder.layer.4.attention.output.dense.weight False\n",
      "feature_extractor.encoder.layer.4.attention.output.dense.bias False\n",
      "feature_extractor.encoder.layer.4.attention.output.LayerNorm.weight False\n",
      "feature_extractor.encoder.layer.4.attention.output.LayerNorm.bias False\n",
      "feature_extractor.encoder.layer.4.intermediate.dense.weight False\n",
      "feature_extractor.encoder.layer.4.intermediate.dense.bias False\n",
      "feature_extractor.encoder.layer.4.output.dense.weight False\n",
      "feature_extractor.encoder.layer.4.output.dense.bias False\n",
      "feature_extractor.encoder.layer.4.output.LayerNorm.weight False\n",
      "feature_extractor.encoder.layer.4.output.LayerNorm.bias False\n",
      "feature_extractor.encoder.layer.5.attention.self.query.weight False\n",
      "feature_extractor.encoder.layer.5.attention.self.query.bias False\n",
      "feature_extractor.encoder.layer.5.attention.self.key.weight False\n",
      "feature_extractor.encoder.layer.5.attention.self.key.bias False\n",
      "feature_extractor.encoder.layer.5.attention.self.value.weight False\n",
      "feature_extractor.encoder.layer.5.attention.self.value.bias False\n",
      "feature_extractor.encoder.layer.5.attention.output.dense.weight False\n",
      "feature_extractor.encoder.layer.5.attention.output.dense.bias False\n",
      "feature_extractor.encoder.layer.5.attention.output.LayerNorm.weight False\n",
      "feature_extractor.encoder.layer.5.attention.output.LayerNorm.bias False\n",
      "feature_extractor.encoder.layer.5.intermediate.dense.weight False\n",
      "feature_extractor.encoder.layer.5.intermediate.dense.bias False\n",
      "feature_extractor.encoder.layer.5.output.dense.weight False\n",
      "feature_extractor.encoder.layer.5.output.dense.bias False\n",
      "feature_extractor.encoder.layer.5.output.LayerNorm.weight False\n",
      "feature_extractor.encoder.layer.5.output.LayerNorm.bias False\n",
      "feature_extractor.encoder.layer.6.attention.self.query.weight False\n",
      "feature_extractor.encoder.layer.6.attention.self.query.bias False\n",
      "feature_extractor.encoder.layer.6.attention.self.key.weight False\n",
      "feature_extractor.encoder.layer.6.attention.self.key.bias False\n",
      "feature_extractor.encoder.layer.6.attention.self.value.weight False\n",
      "feature_extractor.encoder.layer.6.attention.self.value.bias False\n",
      "feature_extractor.encoder.layer.6.attention.output.dense.weight False\n",
      "feature_extractor.encoder.layer.6.attention.output.dense.bias False\n",
      "feature_extractor.encoder.layer.6.attention.output.LayerNorm.weight False\n",
      "feature_extractor.encoder.layer.6.attention.output.LayerNorm.bias False\n",
      "feature_extractor.encoder.layer.6.intermediate.dense.weight False\n",
      "feature_extractor.encoder.layer.6.intermediate.dense.bias False\n",
      "feature_extractor.encoder.layer.6.output.dense.weight False\n",
      "feature_extractor.encoder.layer.6.output.dense.bias False\n",
      "feature_extractor.encoder.layer.6.output.LayerNorm.weight False\n",
      "feature_extractor.encoder.layer.6.output.LayerNorm.bias False\n",
      "feature_extractor.encoder.layer.7.attention.self.query.weight False\n",
      "feature_extractor.encoder.layer.7.attention.self.query.bias False\n",
      "feature_extractor.encoder.layer.7.attention.self.key.weight False\n",
      "feature_extractor.encoder.layer.7.attention.self.key.bias False\n",
      "feature_extractor.encoder.layer.7.attention.self.value.weight False\n",
      "feature_extractor.encoder.layer.7.attention.self.value.bias False\n",
      "feature_extractor.encoder.layer.7.attention.output.dense.weight False\n",
      "feature_extractor.encoder.layer.7.attention.output.dense.bias False\n",
      "feature_extractor.encoder.layer.7.attention.output.LayerNorm.weight False\n",
      "feature_extractor.encoder.layer.7.attention.output.LayerNorm.bias False\n",
      "feature_extractor.encoder.layer.7.intermediate.dense.weight False\n",
      "feature_extractor.encoder.layer.7.intermediate.dense.bias False\n",
      "feature_extractor.encoder.layer.7.output.dense.weight False\n",
      "feature_extractor.encoder.layer.7.output.dense.bias False\n",
      "feature_extractor.encoder.layer.7.output.LayerNorm.weight False\n",
      "feature_extractor.encoder.layer.7.output.LayerNorm.bias False\n",
      "feature_extractor.encoder.layer.8.attention.self.query.weight False\n",
      "feature_extractor.encoder.layer.8.attention.self.query.bias False\n",
      "feature_extractor.encoder.layer.8.attention.self.key.weight False\n",
      "feature_extractor.encoder.layer.8.attention.self.key.bias False\n",
      "feature_extractor.encoder.layer.8.attention.self.value.weight False\n",
      "feature_extractor.encoder.layer.8.attention.self.value.bias False\n",
      "feature_extractor.encoder.layer.8.attention.output.dense.weight False\n",
      "feature_extractor.encoder.layer.8.attention.output.dense.bias False\n",
      "feature_extractor.encoder.layer.8.attention.output.LayerNorm.weight False\n",
      "feature_extractor.encoder.layer.8.attention.output.LayerNorm.bias False\n",
      "feature_extractor.encoder.layer.8.intermediate.dense.weight False\n",
      "feature_extractor.encoder.layer.8.intermediate.dense.bias False\n",
      "feature_extractor.encoder.layer.8.output.dense.weight False\n",
      "feature_extractor.encoder.layer.8.output.dense.bias False\n",
      "feature_extractor.encoder.layer.8.output.LayerNorm.weight False\n",
      "feature_extractor.encoder.layer.8.output.LayerNorm.bias False\n",
      "feature_extractor.encoder.layer.9.attention.self.query.weight False\n",
      "feature_extractor.encoder.layer.9.attention.self.query.bias False\n",
      "feature_extractor.encoder.layer.9.attention.self.key.weight False\n",
      "feature_extractor.encoder.layer.9.attention.self.key.bias False\n",
      "feature_extractor.encoder.layer.9.attention.self.value.weight False\n",
      "feature_extractor.encoder.layer.9.attention.self.value.bias False\n",
      "feature_extractor.encoder.layer.9.attention.output.dense.weight False\n",
      "feature_extractor.encoder.layer.9.attention.output.dense.bias False\n",
      "feature_extractor.encoder.layer.9.attention.output.LayerNorm.weight False\n",
      "feature_extractor.encoder.layer.9.attention.output.LayerNorm.bias False\n",
      "feature_extractor.encoder.layer.9.intermediate.dense.weight False\n",
      "feature_extractor.encoder.layer.9.intermediate.dense.bias False\n",
      "feature_extractor.encoder.layer.9.output.dense.weight False\n",
      "feature_extractor.encoder.layer.9.output.dense.bias False\n",
      "feature_extractor.encoder.layer.9.output.LayerNorm.weight False\n",
      "feature_extractor.encoder.layer.9.output.LayerNorm.bias False\n",
      "feature_extractor.encoder.layer.10.attention.self.query.weight False\n",
      "feature_extractor.encoder.layer.10.attention.self.query.bias False\n",
      "feature_extractor.encoder.layer.10.attention.self.key.weight False\n",
      "feature_extractor.encoder.layer.10.attention.self.key.bias False\n",
      "feature_extractor.encoder.layer.10.attention.self.value.weight False\n",
      "feature_extractor.encoder.layer.10.attention.self.value.bias False\n",
      "feature_extractor.encoder.layer.10.attention.output.dense.weight False\n",
      "feature_extractor.encoder.layer.10.attention.output.dense.bias False\n",
      "feature_extractor.encoder.layer.10.attention.output.LayerNorm.weight False\n",
      "feature_extractor.encoder.layer.10.attention.output.LayerNorm.bias False\n",
      "feature_extractor.encoder.layer.10.intermediate.dense.weight False\n",
      "feature_extractor.encoder.layer.10.intermediate.dense.bias False\n",
      "feature_extractor.encoder.layer.10.output.dense.weight False\n",
      "feature_extractor.encoder.layer.10.output.dense.bias False\n",
      "feature_extractor.encoder.layer.10.output.LayerNorm.weight False\n",
      "feature_extractor.encoder.layer.10.output.LayerNorm.bias False\n",
      "feature_extractor.encoder.layer.11.attention.self.query.weight False\n",
      "feature_extractor.encoder.layer.11.attention.self.query.bias False\n",
      "feature_extractor.encoder.layer.11.attention.self.key.weight False\n",
      "feature_extractor.encoder.layer.11.attention.self.key.bias False\n",
      "feature_extractor.encoder.layer.11.attention.self.value.weight False\n",
      "feature_extractor.encoder.layer.11.attention.self.value.bias False\n",
      "feature_extractor.encoder.layer.11.attention.output.dense.weight False\n",
      "feature_extractor.encoder.layer.11.attention.output.dense.bias False\n",
      "feature_extractor.encoder.layer.11.attention.output.LayerNorm.weight False\n",
      "feature_extractor.encoder.layer.11.attention.output.LayerNorm.bias False\n",
      "feature_extractor.encoder.layer.11.intermediate.dense.weight False\n",
      "feature_extractor.encoder.layer.11.intermediate.dense.bias False\n",
      "feature_extractor.encoder.layer.11.output.dense.weight False\n",
      "feature_extractor.encoder.layer.11.output.dense.bias False\n",
      "feature_extractor.encoder.layer.11.output.LayerNorm.weight False\n",
      "feature_extractor.encoder.layer.11.output.LayerNorm.bias False\n",
      "feature_extractor.pooler.dense.weight True\n",
      "feature_extractor.pooler.dense.bias True\n",
      "head.weight True\n",
      "head.bias True\n",
      "arc.W True\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "4it [00:00,  9.31it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train loss: 9.712681770324707\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "25it [00:01, 21.95it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train loss: 9.710326694306874\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "43it [00:02, 22.84it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train loss: 9.740931464404595\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "64it [00:03, 22.95it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train loss: 9.749955005333073\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "85it [00:04, 23.01it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train loss: 9.778918466450255\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "103it [00:04, 22.97it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train loss: 9.812658149417084\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "124it [00:05, 22.96it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train loss: 9.832943766570288\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "145it [00:06, 22.95it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train loss: 9.835337652382275\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "163it [00:07, 22.92it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train loss: 9.83851052515255\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "184it [00:08, 22.93it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train loss: 9.855037041131963\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "205it [00:09, 22.66it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train loss: 9.870732990663443\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "225it [00:10, 22.12it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train loss: 9.885637909039113\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████| 225/225 [00:08<00:00, 25.29it/s]\n",
      "100%|███████████████████████████████████████████| 61/61 [00:02<00:00, 23.33it/s]\n",
      "/mnt/disk2/ndubrovnyi/words_similarity/.venv/lib/python3.8/site-packages/sklearn/neighbors/_nearest_centroid.py:168: UserWarning: Averaging for metrics other than euclidean and manhattan not supported. The average is set to be the mean.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1\n",
      "Train Loss: 9.888797310723199\n",
      "ACC@3: 0.019339865910263022\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "5it [00:00, 20.57it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train loss: 10.143267631530762\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "23it [00:01, 22.56it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train loss: 10.065919966924758\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "44it [00:01, 22.68it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train loss: 10.019228400253668\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "65it [00:02, 22.64it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train loss: 9.994966147375889\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "83it [00:03, 22.64it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train loss: 9.994098875257704\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "104it [00:04, 22.67it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train loss: 10.013776420366646\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "125it [00:05, 22.66it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train loss: 10.03664284698234\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "143it [00:06, 22.62it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train loss: 10.033339500427246\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "164it [00:07, 22.64it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train loss: 10.01563929326786\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "185it [00:08, 22.58it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train loss: 9.999219688921343\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "203it [00:08, 22.58it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train loss: 9.987236521137294\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "224it [00:09, 22.58it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train loss: 9.969883254210874\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "225it [00:09, 22.51it/s]\n",
      "100%|█████████████████████████████████████████| 225/225 [00:09<00:00, 24.85it/s]\n",
      "100%|███████████████████████████████████████████| 61/61 [00:02<00:00, 23.42it/s]\n",
      "/mnt/disk2/ndubrovnyi/words_similarity/.venv/lib/python3.8/site-packages/sklearn/neighbors/_nearest_centroid.py:168: UserWarning: Averaging for metrics other than euclidean and manhattan not supported. The average is set to be the mean.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 2\n",
      "Train Loss: 9.965960782368978\n",
      "ACC@3: 0.007735946364105209\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "5it [00:00, 18.23it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train loss: 9.692327499389648\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "23it [00:01, 22.21it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train loss: 9.783634503682455\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "44it [00:02, 22.44it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train loss: 9.713041584666183\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "65it [00:02, 22.44it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train loss: 9.612036407970992\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "83it [00:03, 22.42it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train loss: 9.487029558346595\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "104it [00:04, 22.39it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train loss: 9.39679493290363\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "125it [00:05, 22.42it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train loss: 9.342996195328137\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "143it [00:06, 22.40it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train loss: 9.309635507299545\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "164it [00:07, 22.41it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train loss: 9.287230876661976\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "185it [00:08, 22.38it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train loss: 9.2684402096996\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "203it [00:09, 22.40it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train loss: 9.256536312957309\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "225it [00:10, 22.25it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train loss: 9.250462217028863\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|█████████████████████████████████████████| 225/225 [00:09<00:00, 24.71it/s]\n",
      "100%|███████████████████████████████████████████| 61/61 [00:02<00:00, 23.34it/s]\n",
      "/mnt/disk2/ndubrovnyi/words_similarity/.venv/lib/python3.8/site-packages/sklearn/neighbors/_nearest_centroid.py:168: UserWarning: Averaging for metrics other than euclidean and manhattan not supported. The average is set to be the mean.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 3\n",
      "Train Loss: 9.250724792480469\n",
      "ACC@3: 0.00850954100051573\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "5it [00:00, 18.77it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train loss: 7.750965595245361\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "23it [00:01, 22.02it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train loss: 7.481003034682501\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "44it [00:02, 22.20it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train loss: 7.351738615733821\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "65it [00:02, 22.24it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train loss: 7.332328061588475\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "83it [00:03, 22.22it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train loss: 7.358834555119644\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "104it [00:04, 22.19it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train loss: 7.395584276407072\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "125it [00:05, 22.20it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train loss: 7.422162627385667\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "143it [00:06, 22.19it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train loss: 7.446005848282618\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "164it [00:07, 22.24it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train loss: 7.4737536714684145\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "185it [00:08, 22.21it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train loss: 7.4998321664926095\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "203it [00:09, 22.21it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train loss: 7.519303103584555\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "224it [00:10, 22.20it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train loss: 7.547551659976735\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "225it [00:10, 22.05it/s]\n",
      "100%|█████████████████████████████████████████| 225/225 [00:09<00:00, 24.27it/s]\n",
      "100%|███████████████████████████████████████████| 61/61 [00:02<00:00, 22.84it/s]\n",
      "/mnt/disk2/ndubrovnyi/words_similarity/.venv/lib/python3.8/site-packages/sklearn/neighbors/_nearest_centroid.py:168: UserWarning: Averaging for metrics other than euclidean and manhattan not supported. The average is set to be the mean.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 4\n",
      "Train Loss: 7.5521525149875215\n",
      "ACC@3: 0.22331098504383703\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "5it [00:00, 18.23it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train loss: 5.448383331298828\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "23it [00:01, 21.84it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train loss: 5.241069861820766\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "44it [00:02, 22.08it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train loss: 5.218508708767775\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "65it [00:03, 21.94it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train loss: 5.25229549407959\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "83it [00:03, 21.93it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train loss: 5.274244538059941\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "104it [00:04, 21.92it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train loss: 5.294750662133245\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "125it [00:05, 21.95it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train loss: 5.324664123787367\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "143it [00:06, 22.00it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train loss: 5.352980752363273\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "164it [00:07, 22.07it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train loss: 5.384190822980418\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "185it [00:08, 22.02it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train loss: 5.41418049743821\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "203it [00:09, 22.05it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train loss: 5.445337039321216\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "224it [00:10, 22.01it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train loss: 5.473553405088537\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "225it [00:10, 21.84it/s]\n",
      "100%|█████████████████████████████████████████| 225/225 [00:09<00:00, 24.27it/s]\n",
      "100%|███████████████████████████████████████████| 61/61 [00:02<00:00, 22.92it/s]\n",
      "/mnt/disk2/ndubrovnyi/words_similarity/.venv/lib/python3.8/site-packages/sklearn/neighbors/_nearest_centroid.py:168: UserWarning: Averaging for metrics other than euclidean and manhattan not supported. The average is set to be the mean.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 5\n",
      "Train Loss: 5.47841097301907\n",
      "ACC@3: 0.4767921609076844\n",
      "feature_extractor.embeddings.word_embeddings.weight False\n",
      "feature_extractor.embeddings.position_embeddings.weight False\n",
      "feature_extractor.embeddings.token_type_embeddings.weight False\n",
      "feature_extractor.embeddings.LayerNorm.weight False\n",
      "feature_extractor.embeddings.LayerNorm.bias False\n",
      "feature_extractor.encoder.layer.0.attention.self.query.weight False\n",
      "feature_extractor.encoder.layer.0.attention.self.query.bias False\n",
      "feature_extractor.encoder.layer.0.attention.self.key.weight False\n",
      "feature_extractor.encoder.layer.0.attention.self.key.bias False\n",
      "feature_extractor.encoder.layer.0.attention.self.value.weight False\n",
      "feature_extractor.encoder.layer.0.attention.self.value.bias False\n",
      "feature_extractor.encoder.layer.0.attention.output.dense.weight False\n",
      "feature_extractor.encoder.layer.0.attention.output.dense.bias False\n",
      "feature_extractor.encoder.layer.0.attention.output.LayerNorm.weight False\n",
      "feature_extractor.encoder.layer.0.attention.output.LayerNorm.bias False\n",
      "feature_extractor.encoder.layer.0.intermediate.dense.weight False\n",
      "feature_extractor.encoder.layer.0.intermediate.dense.bias False\n",
      "feature_extractor.encoder.layer.0.output.dense.weight False\n",
      "feature_extractor.encoder.layer.0.output.dense.bias False\n",
      "feature_extractor.encoder.layer.0.output.LayerNorm.weight False\n",
      "feature_extractor.encoder.layer.0.output.LayerNorm.bias False\n",
      "feature_extractor.encoder.layer.1.attention.self.query.weight False\n",
      "feature_extractor.encoder.layer.1.attention.self.query.bias False\n",
      "feature_extractor.encoder.layer.1.attention.self.key.weight False\n",
      "feature_extractor.encoder.layer.1.attention.self.key.bias False\n",
      "feature_extractor.encoder.layer.1.attention.self.value.weight False\n",
      "feature_extractor.encoder.layer.1.attention.self.value.bias False\n",
      "feature_extractor.encoder.layer.1.attention.output.dense.weight False\n",
      "feature_extractor.encoder.layer.1.attention.output.dense.bias False\n",
      "feature_extractor.encoder.layer.1.attention.output.LayerNorm.weight False\n",
      "feature_extractor.encoder.layer.1.attention.output.LayerNorm.bias False\n",
      "feature_extractor.encoder.layer.1.intermediate.dense.weight False\n",
      "feature_extractor.encoder.layer.1.intermediate.dense.bias False\n",
      "feature_extractor.encoder.layer.1.output.dense.weight False\n",
      "feature_extractor.encoder.layer.1.output.dense.bias False\n",
      "feature_extractor.encoder.layer.1.output.LayerNorm.weight False\n",
      "feature_extractor.encoder.layer.1.output.LayerNorm.bias False\n",
      "feature_extractor.encoder.layer.2.attention.self.query.weight False\n",
      "feature_extractor.encoder.layer.2.attention.self.query.bias False\n",
      "feature_extractor.encoder.layer.2.attention.self.key.weight False\n",
      "feature_extractor.encoder.layer.2.attention.self.key.bias False\n",
      "feature_extractor.encoder.layer.2.attention.self.value.weight False\n",
      "feature_extractor.encoder.layer.2.attention.self.value.bias False\n",
      "feature_extractor.encoder.layer.2.attention.output.dense.weight False\n",
      "feature_extractor.encoder.layer.2.attention.output.dense.bias False\n",
      "feature_extractor.encoder.layer.2.attention.output.LayerNorm.weight False\n",
      "feature_extractor.encoder.layer.2.attention.output.LayerNorm.bias False\n",
      "feature_extractor.encoder.layer.2.intermediate.dense.weight False\n",
      "feature_extractor.encoder.layer.2.intermediate.dense.bias False\n",
      "feature_extractor.encoder.layer.2.output.dense.weight False\n",
      "feature_extractor.encoder.layer.2.output.dense.bias False\n",
      "feature_extractor.encoder.layer.2.output.LayerNorm.weight False\n",
      "feature_extractor.encoder.layer.2.output.LayerNorm.bias False\n",
      "feature_extractor.encoder.layer.3.attention.self.query.weight False\n",
      "feature_extractor.encoder.layer.3.attention.self.query.bias False\n",
      "feature_extractor.encoder.layer.3.attention.self.key.weight False\n",
      "feature_extractor.encoder.layer.3.attention.self.key.bias False\n",
      "feature_extractor.encoder.layer.3.attention.self.value.weight False\n",
      "feature_extractor.encoder.layer.3.attention.self.value.bias False\n",
      "feature_extractor.encoder.layer.3.attention.output.dense.weight False\n",
      "feature_extractor.encoder.layer.3.attention.output.dense.bias False\n",
      "feature_extractor.encoder.layer.3.attention.output.LayerNorm.weight False\n",
      "feature_extractor.encoder.layer.3.attention.output.LayerNorm.bias False\n",
      "feature_extractor.encoder.layer.3.intermediate.dense.weight False\n",
      "feature_extractor.encoder.layer.3.intermediate.dense.bias False\n",
      "feature_extractor.encoder.layer.3.output.dense.weight False\n",
      "feature_extractor.encoder.layer.3.output.dense.bias False\n",
      "feature_extractor.encoder.layer.3.output.LayerNorm.weight False\n",
      "feature_extractor.encoder.layer.3.output.LayerNorm.bias False\n",
      "feature_extractor.encoder.layer.4.attention.self.query.weight False\n",
      "feature_extractor.encoder.layer.4.attention.self.query.bias False\n",
      "feature_extractor.encoder.layer.4.attention.self.key.weight False\n",
      "feature_extractor.encoder.layer.4.attention.self.key.bias False\n",
      "feature_extractor.encoder.layer.4.attention.self.value.weight False\n",
      "feature_extractor.encoder.layer.4.attention.self.value.bias False\n",
      "feature_extractor.encoder.layer.4.attention.output.dense.weight False\n",
      "feature_extractor.encoder.layer.4.attention.output.dense.bias False\n",
      "feature_extractor.encoder.layer.4.attention.output.LayerNorm.weight False\n",
      "feature_extractor.encoder.layer.4.attention.output.LayerNorm.bias False\n",
      "feature_extractor.encoder.layer.4.intermediate.dense.weight False\n",
      "feature_extractor.encoder.layer.4.intermediate.dense.bias False\n",
      "feature_extractor.encoder.layer.4.output.dense.weight False\n",
      "feature_extractor.encoder.layer.4.output.dense.bias False\n",
      "feature_extractor.encoder.layer.4.output.LayerNorm.weight False\n",
      "feature_extractor.encoder.layer.4.output.LayerNorm.bias False\n",
      "feature_extractor.encoder.layer.5.attention.self.query.weight False\n",
      "feature_extractor.encoder.layer.5.attention.self.query.bias False\n",
      "feature_extractor.encoder.layer.5.attention.self.key.weight False\n",
      "feature_extractor.encoder.layer.5.attention.self.key.bias False\n",
      "feature_extractor.encoder.layer.5.attention.self.value.weight False\n",
      "feature_extractor.encoder.layer.5.attention.self.value.bias False\n",
      "feature_extractor.encoder.layer.5.attention.output.dense.weight False\n",
      "feature_extractor.encoder.layer.5.attention.output.dense.bias False\n",
      "feature_extractor.encoder.layer.5.attention.output.LayerNorm.weight False\n",
      "feature_extractor.encoder.layer.5.attention.output.LayerNorm.bias False\n",
      "feature_extractor.encoder.layer.5.intermediate.dense.weight False\n",
      "feature_extractor.encoder.layer.5.intermediate.dense.bias False\n",
      "feature_extractor.encoder.layer.5.output.dense.weight False\n",
      "feature_extractor.encoder.layer.5.output.dense.bias False\n",
      "feature_extractor.encoder.layer.5.output.LayerNorm.weight False\n",
      "feature_extractor.encoder.layer.5.output.LayerNorm.bias False\n",
      "feature_extractor.encoder.layer.6.attention.self.query.weight False\n",
      "feature_extractor.encoder.layer.6.attention.self.query.bias False\n",
      "feature_extractor.encoder.layer.6.attention.self.key.weight False\n",
      "feature_extractor.encoder.layer.6.attention.self.key.bias False\n",
      "feature_extractor.encoder.layer.6.attention.self.value.weight False\n",
      "feature_extractor.encoder.layer.6.attention.self.value.bias False\n",
      "feature_extractor.encoder.layer.6.attention.output.dense.weight False\n",
      "feature_extractor.encoder.layer.6.attention.output.dense.bias False\n",
      "feature_extractor.encoder.layer.6.attention.output.LayerNorm.weight False\n",
      "feature_extractor.encoder.layer.6.attention.output.LayerNorm.bias False\n",
      "feature_extractor.encoder.layer.6.intermediate.dense.weight False\n",
      "feature_extractor.encoder.layer.6.intermediate.dense.bias False\n",
      "feature_extractor.encoder.layer.6.output.dense.weight False\n",
      "feature_extractor.encoder.layer.6.output.dense.bias False\n",
      "feature_extractor.encoder.layer.6.output.LayerNorm.weight False\n",
      "feature_extractor.encoder.layer.6.output.LayerNorm.bias False\n",
      "feature_extractor.encoder.layer.7.attention.self.query.weight False\n",
      "feature_extractor.encoder.layer.7.attention.self.query.bias False\n",
      "feature_extractor.encoder.layer.7.attention.self.key.weight False\n",
      "feature_extractor.encoder.layer.7.attention.self.key.bias False\n",
      "feature_extractor.encoder.layer.7.attention.self.value.weight False\n",
      "feature_extractor.encoder.layer.7.attention.self.value.bias False\n",
      "feature_extractor.encoder.layer.7.attention.output.dense.weight False\n",
      "feature_extractor.encoder.layer.7.attention.output.dense.bias False\n",
      "feature_extractor.encoder.layer.7.attention.output.LayerNorm.weight False\n",
      "feature_extractor.encoder.layer.7.attention.output.LayerNorm.bias False\n",
      "feature_extractor.encoder.layer.7.intermediate.dense.weight False\n",
      "feature_extractor.encoder.layer.7.intermediate.dense.bias False\n",
      "feature_extractor.encoder.layer.7.output.dense.weight False\n",
      "feature_extractor.encoder.layer.7.output.dense.bias False\n",
      "feature_extractor.encoder.layer.7.output.LayerNorm.weight False\n",
      "feature_extractor.encoder.layer.7.output.LayerNorm.bias False\n",
      "feature_extractor.encoder.layer.8.attention.self.query.weight False\n",
      "feature_extractor.encoder.layer.8.attention.self.query.bias False\n",
      "feature_extractor.encoder.layer.8.attention.self.key.weight False\n",
      "feature_extractor.encoder.layer.8.attention.self.key.bias False\n",
      "feature_extractor.encoder.layer.8.attention.self.value.weight False\n",
      "feature_extractor.encoder.layer.8.attention.self.value.bias False\n",
      "feature_extractor.encoder.layer.8.attention.output.dense.weight False\n",
      "feature_extractor.encoder.layer.8.attention.output.dense.bias False\n",
      "feature_extractor.encoder.layer.8.attention.output.LayerNorm.weight False\n",
      "feature_extractor.encoder.layer.8.attention.output.LayerNorm.bias False\n",
      "feature_extractor.encoder.layer.8.intermediate.dense.weight False\n",
      "feature_extractor.encoder.layer.8.intermediate.dense.bias False\n",
      "feature_extractor.encoder.layer.8.output.dense.weight False\n",
      "feature_extractor.encoder.layer.8.output.dense.bias False\n",
      "feature_extractor.encoder.layer.8.output.LayerNorm.weight False\n",
      "feature_extractor.encoder.layer.8.output.LayerNorm.bias False\n",
      "feature_extractor.encoder.layer.9.attention.self.query.weight False\n",
      "feature_extractor.encoder.layer.9.attention.self.query.bias False\n",
      "feature_extractor.encoder.layer.9.attention.self.key.weight False\n",
      "feature_extractor.encoder.layer.9.attention.self.key.bias False\n",
      "feature_extractor.encoder.layer.9.attention.self.value.weight False\n",
      "feature_extractor.encoder.layer.9.attention.self.value.bias False\n",
      "feature_extractor.encoder.layer.9.attention.output.dense.weight False\n",
      "feature_extractor.encoder.layer.9.attention.output.dense.bias False\n",
      "feature_extractor.encoder.layer.9.attention.output.LayerNorm.weight False\n",
      "feature_extractor.encoder.layer.9.attention.output.LayerNorm.bias False\n",
      "feature_extractor.encoder.layer.9.intermediate.dense.weight False\n",
      "feature_extractor.encoder.layer.9.intermediate.dense.bias False\n",
      "feature_extractor.encoder.layer.9.output.dense.weight False\n",
      "feature_extractor.encoder.layer.9.output.dense.bias False\n",
      "feature_extractor.encoder.layer.9.output.LayerNorm.weight False\n",
      "feature_extractor.encoder.layer.9.output.LayerNorm.bias False\n",
      "feature_extractor.encoder.layer.10.attention.self.query.weight False\n",
      "feature_extractor.encoder.layer.10.attention.self.query.bias False\n",
      "feature_extractor.encoder.layer.10.attention.self.key.weight False\n",
      "feature_extractor.encoder.layer.10.attention.self.key.bias False\n",
      "feature_extractor.encoder.layer.10.attention.self.value.weight False\n",
      "feature_extractor.encoder.layer.10.attention.self.value.bias False\n",
      "feature_extractor.encoder.layer.10.attention.output.dense.weight False\n",
      "feature_extractor.encoder.layer.10.attention.output.dense.bias False\n",
      "feature_extractor.encoder.layer.10.attention.output.LayerNorm.weight False\n",
      "feature_extractor.encoder.layer.10.attention.output.LayerNorm.bias False\n",
      "feature_extractor.encoder.layer.10.intermediate.dense.weight False\n",
      "feature_extractor.encoder.layer.10.intermediate.dense.bias False\n",
      "feature_extractor.encoder.layer.10.output.dense.weight False\n",
      "feature_extractor.encoder.layer.10.output.dense.bias False\n",
      "feature_extractor.encoder.layer.10.output.LayerNorm.weight False\n",
      "feature_extractor.encoder.layer.10.output.LayerNorm.bias False\n",
      "feature_extractor.encoder.layer.11.attention.self.query.weight True\n",
      "feature_extractor.encoder.layer.11.attention.self.query.bias True\n",
      "feature_extractor.encoder.layer.11.attention.self.key.weight True\n",
      "feature_extractor.encoder.layer.11.attention.self.key.bias True\n",
      "feature_extractor.encoder.layer.11.attention.self.value.weight True\n",
      "feature_extractor.encoder.layer.11.attention.self.value.bias True\n",
      "feature_extractor.encoder.layer.11.attention.output.dense.weight True\n",
      "feature_extractor.encoder.layer.11.attention.output.dense.bias True\n",
      "feature_extractor.encoder.layer.11.attention.output.LayerNorm.weight True\n",
      "feature_extractor.encoder.layer.11.attention.output.LayerNorm.bias True\n",
      "feature_extractor.encoder.layer.11.intermediate.dense.weight True\n",
      "feature_extractor.encoder.layer.11.intermediate.dense.bias True\n",
      "feature_extractor.encoder.layer.11.output.dense.weight True\n",
      "feature_extractor.encoder.layer.11.output.dense.bias True\n",
      "feature_extractor.encoder.layer.11.output.LayerNorm.weight True\n",
      "feature_extractor.encoder.layer.11.output.LayerNorm.bias True\n",
      "feature_extractor.pooler.dense.weight True\n",
      "feature_extractor.pooler.dense.bias True\n",
      "head.weight True\n",
      "head.bias True\n",
      "arc.W True\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "4it [00:00, 16.32it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train loss: 3.6322104930877686\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "24it [00:01, 19.32it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train loss: 3.39544567607698\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "44it [00:02, 19.35it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train loss: 3.348180073063548\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "64it [00:03, 19.36it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train loss: 3.346110156325043\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "84it [00:04, 19.36it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train loss: 3.3631742795308432\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "104it [00:05, 19.36it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train loss: 3.395076867377404\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "124it [00:06, 19.33it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train loss: 3.4043439636545734\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "144it [00:07, 19.33it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train loss: 3.4206709455936513\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "164it [00:08, 19.35it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train loss: 3.4401388731062044\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "184it [00:09, 19.34it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train loss: 3.458064083236357\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "204it [00:10, 19.33it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train loss: 3.4831283673718203\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "224it [00:11, 19.36it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train loss: 3.5050073576189273\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "225it [00:11, 19.24it/s]\n",
      "100%|█████████████████████████████████████████| 225/225 [00:09<00:00, 24.21it/s]\n",
      "100%|███████████████████████████████████████████| 61/61 [00:02<00:00, 22.82it/s]\n",
      "/mnt/disk2/ndubrovnyi/words_similarity/.venv/lib/python3.8/site-packages/sklearn/neighbors/_nearest_centroid.py:168: UserWarning: Averaging for metrics other than euclidean and manhattan not supported. The average is set to be the mean.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 6\n",
      "Train Loss: 3.5075172932942706\n",
      "ACC@3: 0.8197524497163486\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "4it [00:00, 16.24it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train loss: 1.7645518779754639\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "24it [00:01, 19.40it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train loss: 1.8139445668175107\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "44it [00:02, 19.39it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train loss: 1.8337939221684525\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "64it [00:03, 19.40it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train loss: 1.8506489659919114\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "84it [00:04, 19.39it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train loss: 1.8514189072597174\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "104it [00:05, 19.41it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train loss: 1.864267392913894\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "124it [00:06, 19.44it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train loss: 1.8833285905112904\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "144it [00:07, 19.43it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train loss: 1.8995507473641253\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "164it [00:08, 19.40it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train loss: 1.912009074080805\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "184it [00:09, 19.43it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train loss: 1.9276432925166347\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "204it [00:10, 19.42it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train loss: 1.9409488006610776\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "224it [00:11, 19.42it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train loss: 1.9570471167024983\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "225it [00:11, 19.33it/s]\n",
      "100%|█████████████████████████████████████████| 225/225 [00:09<00:00, 24.23it/s]\n",
      "100%|███████████████████████████████████████████| 61/61 [00:02<00:00, 22.83it/s]\n",
      "/mnt/disk2/ndubrovnyi/words_similarity/.venv/lib/python3.8/site-packages/sklearn/neighbors/_nearest_centroid.py:168: UserWarning: Averaging for metrics other than euclidean and manhattan not supported. The average is set to be the mean.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 7\n",
      "Train Loss: 1.9605478641721938\n",
      "ACC@3: 0.8548220732336256\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "4it [00:00, 15.77it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train loss: 0.9356658458709717\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "24it [00:01, 19.21it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train loss: 1.0259149301619757\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "44it [00:02, 19.32it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train loss: 1.0056065582647555\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "64it [00:03, 19.30it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train loss: 0.99802294324656\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "84it [00:04, 19.29it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train loss: 0.9966029583671947\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "104it [00:05, 19.31it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train loss: 1.0005136686976592\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "124it [00:06, 19.31it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train loss: 1.0095194376204624\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "144it [00:07, 19.30it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train loss: 1.0215835013288133\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "164it [00:08, 19.28it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train loss: 1.0275800820463192\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "184it [00:09, 19.28it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train loss: 1.0332388917385544\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "204it [00:10, 19.27it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train loss: 1.0435048335820287\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "224it [00:11, 19.28it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train loss: 1.0515376081294063\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "225it [00:11, 19.17it/s]\n",
      "100%|█████████████████████████████████████████| 225/225 [00:09<00:00, 24.02it/s]\n",
      "100%|███████████████████████████████████████████| 61/61 [00:02<00:00, 22.67it/s]\n",
      "/mnt/disk2/ndubrovnyi/words_similarity/.venv/lib/python3.8/site-packages/sklearn/neighbors/_nearest_centroid.py:168: UserWarning: Averaging for metrics other than euclidean and manhattan not supported. The average is set to be the mean.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 8\n",
      "Train Loss: 1.0530544344584147\n",
      "ACC@3: 0.8664259927797834\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "4it [00:00, 15.71it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train loss: 0.74838787317276\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "24it [00:01, 19.24it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train loss: 0.7641485134760538\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "44it [00:02, 19.28it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train loss: 0.7671980959613148\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "64it [00:03, 19.28it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train loss: 0.7680623804936644\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "84it [00:04, 19.27it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train loss: 0.7697327652095277\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "104it [00:05, 19.20it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train loss: 0.7710012828949655\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "124it [00:06, 19.25it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train loss: 0.7706235578237486\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "144it [00:07, 19.24it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train loss: 0.7706065144099242\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "164it [00:08, 19.24it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train loss: 0.7706395854120669\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "184it [00:09, 19.26it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train loss: 0.772886972730331\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "204it [00:10, 19.28it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train loss: 0.772586995096349\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "224it [00:11, 19.24it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train loss: 0.7721557387938867\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "225it [00:11, 19.14it/s]\n",
      "100%|█████████████████████████████████████████| 225/225 [00:09<00:00, 24.15it/s]\n",
      "100%|███████████████████████████████████████████| 61/61 [00:02<00:00, 22.62it/s]\n",
      "/mnt/disk2/ndubrovnyi/words_similarity/.venv/lib/python3.8/site-packages/sklearn/neighbors/_nearest_centroid.py:168: UserWarning: Averaging for metrics other than euclidean and manhattan not supported. The average is set to be the mean.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 9\n",
      "Train Loss: 0.7728617310523986\n",
      "ACC@3: 0.8795771015987622\n",
      "feature_extractor.embeddings.word_embeddings.weight False\n",
      "feature_extractor.embeddings.position_embeddings.weight False\n",
      "feature_extractor.embeddings.token_type_embeddings.weight False\n",
      "feature_extractor.embeddings.LayerNorm.weight False\n",
      "feature_extractor.embeddings.LayerNorm.bias False\n",
      "feature_extractor.encoder.layer.0.attention.self.query.weight False\n",
      "feature_extractor.encoder.layer.0.attention.self.query.bias False\n",
      "feature_extractor.encoder.layer.0.attention.self.key.weight False\n",
      "feature_extractor.encoder.layer.0.attention.self.key.bias False\n",
      "feature_extractor.encoder.layer.0.attention.self.value.weight False\n",
      "feature_extractor.encoder.layer.0.attention.self.value.bias False\n",
      "feature_extractor.encoder.layer.0.attention.output.dense.weight False\n",
      "feature_extractor.encoder.layer.0.attention.output.dense.bias False\n",
      "feature_extractor.encoder.layer.0.attention.output.LayerNorm.weight False\n",
      "feature_extractor.encoder.layer.0.attention.output.LayerNorm.bias False\n",
      "feature_extractor.encoder.layer.0.intermediate.dense.weight False\n",
      "feature_extractor.encoder.layer.0.intermediate.dense.bias False\n",
      "feature_extractor.encoder.layer.0.output.dense.weight False\n",
      "feature_extractor.encoder.layer.0.output.dense.bias False\n",
      "feature_extractor.encoder.layer.0.output.LayerNorm.weight False\n",
      "feature_extractor.encoder.layer.0.output.LayerNorm.bias False\n",
      "feature_extractor.encoder.layer.1.attention.self.query.weight False\n",
      "feature_extractor.encoder.layer.1.attention.self.query.bias False\n",
      "feature_extractor.encoder.layer.1.attention.self.key.weight False\n",
      "feature_extractor.encoder.layer.1.attention.self.key.bias False\n",
      "feature_extractor.encoder.layer.1.attention.self.value.weight False\n",
      "feature_extractor.encoder.layer.1.attention.self.value.bias False\n",
      "feature_extractor.encoder.layer.1.attention.output.dense.weight False\n",
      "feature_extractor.encoder.layer.1.attention.output.dense.bias False\n",
      "feature_extractor.encoder.layer.1.attention.output.LayerNorm.weight False\n",
      "feature_extractor.encoder.layer.1.attention.output.LayerNorm.bias False\n",
      "feature_extractor.encoder.layer.1.intermediate.dense.weight False\n",
      "feature_extractor.encoder.layer.1.intermediate.dense.bias False\n",
      "feature_extractor.encoder.layer.1.output.dense.weight False\n",
      "feature_extractor.encoder.layer.1.output.dense.bias False\n",
      "feature_extractor.encoder.layer.1.output.LayerNorm.weight False\n",
      "feature_extractor.encoder.layer.1.output.LayerNorm.bias False\n",
      "feature_extractor.encoder.layer.2.attention.self.query.weight False\n",
      "feature_extractor.encoder.layer.2.attention.self.query.bias False\n",
      "feature_extractor.encoder.layer.2.attention.self.key.weight False\n",
      "feature_extractor.encoder.layer.2.attention.self.key.bias False\n",
      "feature_extractor.encoder.layer.2.attention.self.value.weight False\n",
      "feature_extractor.encoder.layer.2.attention.self.value.bias False\n",
      "feature_extractor.encoder.layer.2.attention.output.dense.weight False\n",
      "feature_extractor.encoder.layer.2.attention.output.dense.bias False\n",
      "feature_extractor.encoder.layer.2.attention.output.LayerNorm.weight False\n",
      "feature_extractor.encoder.layer.2.attention.output.LayerNorm.bias False\n",
      "feature_extractor.encoder.layer.2.intermediate.dense.weight False\n",
      "feature_extractor.encoder.layer.2.intermediate.dense.bias False\n",
      "feature_extractor.encoder.layer.2.output.dense.weight False\n",
      "feature_extractor.encoder.layer.2.output.dense.bias False\n",
      "feature_extractor.encoder.layer.2.output.LayerNorm.weight False\n",
      "feature_extractor.encoder.layer.2.output.LayerNorm.bias False\n",
      "feature_extractor.encoder.layer.3.attention.self.query.weight False\n",
      "feature_extractor.encoder.layer.3.attention.self.query.bias False\n",
      "feature_extractor.encoder.layer.3.attention.self.key.weight False\n",
      "feature_extractor.encoder.layer.3.attention.self.key.bias False\n",
      "feature_extractor.encoder.layer.3.attention.self.value.weight False\n",
      "feature_extractor.encoder.layer.3.attention.self.value.bias False\n",
      "feature_extractor.encoder.layer.3.attention.output.dense.weight False\n",
      "feature_extractor.encoder.layer.3.attention.output.dense.bias False\n",
      "feature_extractor.encoder.layer.3.attention.output.LayerNorm.weight False\n",
      "feature_extractor.encoder.layer.3.attention.output.LayerNorm.bias False\n",
      "feature_extractor.encoder.layer.3.intermediate.dense.weight False\n",
      "feature_extractor.encoder.layer.3.intermediate.dense.bias False\n",
      "feature_extractor.encoder.layer.3.output.dense.weight False\n",
      "feature_extractor.encoder.layer.3.output.dense.bias False\n",
      "feature_extractor.encoder.layer.3.output.LayerNorm.weight False\n",
      "feature_extractor.encoder.layer.3.output.LayerNorm.bias False\n",
      "feature_extractor.encoder.layer.4.attention.self.query.weight False\n",
      "feature_extractor.encoder.layer.4.attention.self.query.bias False\n",
      "feature_extractor.encoder.layer.4.attention.self.key.weight False\n",
      "feature_extractor.encoder.layer.4.attention.self.key.bias False\n",
      "feature_extractor.encoder.layer.4.attention.self.value.weight False\n",
      "feature_extractor.encoder.layer.4.attention.self.value.bias False\n",
      "feature_extractor.encoder.layer.4.attention.output.dense.weight False\n",
      "feature_extractor.encoder.layer.4.attention.output.dense.bias False\n",
      "feature_extractor.encoder.layer.4.attention.output.LayerNorm.weight False\n",
      "feature_extractor.encoder.layer.4.attention.output.LayerNorm.bias False\n",
      "feature_extractor.encoder.layer.4.intermediate.dense.weight False\n",
      "feature_extractor.encoder.layer.4.intermediate.dense.bias False\n",
      "feature_extractor.encoder.layer.4.output.dense.weight False\n",
      "feature_extractor.encoder.layer.4.output.dense.bias False\n",
      "feature_extractor.encoder.layer.4.output.LayerNorm.weight False\n",
      "feature_extractor.encoder.layer.4.output.LayerNorm.bias False\n",
      "feature_extractor.encoder.layer.5.attention.self.query.weight False\n",
      "feature_extractor.encoder.layer.5.attention.self.query.bias False\n",
      "feature_extractor.encoder.layer.5.attention.self.key.weight False\n",
      "feature_extractor.encoder.layer.5.attention.self.key.bias False\n",
      "feature_extractor.encoder.layer.5.attention.self.value.weight False\n",
      "feature_extractor.encoder.layer.5.attention.self.value.bias False\n",
      "feature_extractor.encoder.layer.5.attention.output.dense.weight False\n",
      "feature_extractor.encoder.layer.5.attention.output.dense.bias False\n",
      "feature_extractor.encoder.layer.5.attention.output.LayerNorm.weight False\n",
      "feature_extractor.encoder.layer.5.attention.output.LayerNorm.bias False\n",
      "feature_extractor.encoder.layer.5.intermediate.dense.weight False\n",
      "feature_extractor.encoder.layer.5.intermediate.dense.bias False\n",
      "feature_extractor.encoder.layer.5.output.dense.weight False\n",
      "feature_extractor.encoder.layer.5.output.dense.bias False\n",
      "feature_extractor.encoder.layer.5.output.LayerNorm.weight False\n",
      "feature_extractor.encoder.layer.5.output.LayerNorm.bias False\n",
      "feature_extractor.encoder.layer.6.attention.self.query.weight False\n",
      "feature_extractor.encoder.layer.6.attention.self.query.bias False\n",
      "feature_extractor.encoder.layer.6.attention.self.key.weight False\n",
      "feature_extractor.encoder.layer.6.attention.self.key.bias False\n",
      "feature_extractor.encoder.layer.6.attention.self.value.weight False\n",
      "feature_extractor.encoder.layer.6.attention.self.value.bias False\n",
      "feature_extractor.encoder.layer.6.attention.output.dense.weight False\n",
      "feature_extractor.encoder.layer.6.attention.output.dense.bias False\n",
      "feature_extractor.encoder.layer.6.attention.output.LayerNorm.weight False\n",
      "feature_extractor.encoder.layer.6.attention.output.LayerNorm.bias False\n",
      "feature_extractor.encoder.layer.6.intermediate.dense.weight False\n",
      "feature_extractor.encoder.layer.6.intermediate.dense.bias False\n",
      "feature_extractor.encoder.layer.6.output.dense.weight False\n",
      "feature_extractor.encoder.layer.6.output.dense.bias False\n",
      "feature_extractor.encoder.layer.6.output.LayerNorm.weight False\n",
      "feature_extractor.encoder.layer.6.output.LayerNorm.bias False\n",
      "feature_extractor.encoder.layer.7.attention.self.query.weight False\n",
      "feature_extractor.encoder.layer.7.attention.self.query.bias False\n",
      "feature_extractor.encoder.layer.7.attention.self.key.weight False\n",
      "feature_extractor.encoder.layer.7.attention.self.key.bias False\n",
      "feature_extractor.encoder.layer.7.attention.self.value.weight False\n",
      "feature_extractor.encoder.layer.7.attention.self.value.bias False\n",
      "feature_extractor.encoder.layer.7.attention.output.dense.weight False\n",
      "feature_extractor.encoder.layer.7.attention.output.dense.bias False\n",
      "feature_extractor.encoder.layer.7.attention.output.LayerNorm.weight False\n",
      "feature_extractor.encoder.layer.7.attention.output.LayerNorm.bias False\n",
      "feature_extractor.encoder.layer.7.intermediate.dense.weight False\n",
      "feature_extractor.encoder.layer.7.intermediate.dense.bias False\n",
      "feature_extractor.encoder.layer.7.output.dense.weight False\n",
      "feature_extractor.encoder.layer.7.output.dense.bias False\n",
      "feature_extractor.encoder.layer.7.output.LayerNorm.weight False\n",
      "feature_extractor.encoder.layer.7.output.LayerNorm.bias False\n",
      "feature_extractor.encoder.layer.8.attention.self.query.weight False\n",
      "feature_extractor.encoder.layer.8.attention.self.query.bias False\n",
      "feature_extractor.encoder.layer.8.attention.self.key.weight False\n",
      "feature_extractor.encoder.layer.8.attention.self.key.bias False\n",
      "feature_extractor.encoder.layer.8.attention.self.value.weight False\n",
      "feature_extractor.encoder.layer.8.attention.self.value.bias False\n",
      "feature_extractor.encoder.layer.8.attention.output.dense.weight False\n",
      "feature_extractor.encoder.layer.8.attention.output.dense.bias False\n",
      "feature_extractor.encoder.layer.8.attention.output.LayerNorm.weight False\n",
      "feature_extractor.encoder.layer.8.attention.output.LayerNorm.bias False\n",
      "feature_extractor.encoder.layer.8.intermediate.dense.weight False\n",
      "feature_extractor.encoder.layer.8.intermediate.dense.bias False\n",
      "feature_extractor.encoder.layer.8.output.dense.weight False\n",
      "feature_extractor.encoder.layer.8.output.dense.bias False\n",
      "feature_extractor.encoder.layer.8.output.LayerNorm.weight False\n",
      "feature_extractor.encoder.layer.8.output.LayerNorm.bias False\n",
      "feature_extractor.encoder.layer.9.attention.self.query.weight False\n",
      "feature_extractor.encoder.layer.9.attention.self.query.bias False\n",
      "feature_extractor.encoder.layer.9.attention.self.key.weight False\n",
      "feature_extractor.encoder.layer.9.attention.self.key.bias False\n",
      "feature_extractor.encoder.layer.9.attention.self.value.weight False\n",
      "feature_extractor.encoder.layer.9.attention.self.value.bias False\n",
      "feature_extractor.encoder.layer.9.attention.output.dense.weight False\n",
      "feature_extractor.encoder.layer.9.attention.output.dense.bias False\n",
      "feature_extractor.encoder.layer.9.attention.output.LayerNorm.weight False\n",
      "feature_extractor.encoder.layer.9.attention.output.LayerNorm.bias False\n",
      "feature_extractor.encoder.layer.9.intermediate.dense.weight False\n",
      "feature_extractor.encoder.layer.9.intermediate.dense.bias False\n",
      "feature_extractor.encoder.layer.9.output.dense.weight False\n",
      "feature_extractor.encoder.layer.9.output.dense.bias False\n",
      "feature_extractor.encoder.layer.9.output.LayerNorm.weight False\n",
      "feature_extractor.encoder.layer.9.output.LayerNorm.bias False\n",
      "feature_extractor.encoder.layer.10.attention.self.query.weight True\n",
      "feature_extractor.encoder.layer.10.attention.self.query.bias True\n",
      "feature_extractor.encoder.layer.10.attention.self.key.weight True\n",
      "feature_extractor.encoder.layer.10.attention.self.key.bias True\n",
      "feature_extractor.encoder.layer.10.attention.self.value.weight True\n",
      "feature_extractor.encoder.layer.10.attention.self.value.bias True\n",
      "feature_extractor.encoder.layer.10.attention.output.dense.weight True\n",
      "feature_extractor.encoder.layer.10.attention.output.dense.bias True\n",
      "feature_extractor.encoder.layer.10.attention.output.LayerNorm.weight True\n",
      "feature_extractor.encoder.layer.10.attention.output.LayerNorm.bias True\n",
      "feature_extractor.encoder.layer.10.intermediate.dense.weight True\n",
      "feature_extractor.encoder.layer.10.intermediate.dense.bias True\n",
      "feature_extractor.encoder.layer.10.output.dense.weight True\n",
      "feature_extractor.encoder.layer.10.output.dense.bias True\n",
      "feature_extractor.encoder.layer.10.output.LayerNorm.weight True\n",
      "feature_extractor.encoder.layer.10.output.LayerNorm.bias True\n",
      "feature_extractor.encoder.layer.11.attention.self.query.weight True\n",
      "feature_extractor.encoder.layer.11.attention.self.query.bias True\n",
      "feature_extractor.encoder.layer.11.attention.self.key.weight True\n",
      "feature_extractor.encoder.layer.11.attention.self.key.bias True\n",
      "feature_extractor.encoder.layer.11.attention.self.value.weight True\n",
      "feature_extractor.encoder.layer.11.attention.self.value.bias True\n",
      "feature_extractor.encoder.layer.11.attention.output.dense.weight True\n",
      "feature_extractor.encoder.layer.11.attention.output.dense.bias True\n",
      "feature_extractor.encoder.layer.11.attention.output.LayerNorm.weight True\n",
      "feature_extractor.encoder.layer.11.attention.output.LayerNorm.bias True\n",
      "feature_extractor.encoder.layer.11.intermediate.dense.weight True\n",
      "feature_extractor.encoder.layer.11.intermediate.dense.bias True\n",
      "feature_extractor.encoder.layer.11.output.dense.weight True\n",
      "feature_extractor.encoder.layer.11.output.dense.bias True\n",
      "feature_extractor.encoder.layer.11.output.LayerNorm.weight True\n",
      "feature_extractor.encoder.layer.11.output.LayerNorm.bias True\n",
      "feature_extractor.pooler.dense.weight True\n",
      "feature_extractor.pooler.dense.bias True\n",
      "head.weight True\n",
      "head.bias True\n",
      "arc.W True\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "3it [00:00, 13.54it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train loss: 0.6660974621772766\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "23it [00:01, 16.99it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train loss: 0.7451920395805722\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "43it [00:02, 17.05it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train loss: 0.751644929734672\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "63it [00:03, 17.03it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train loss: 0.7506637622098453\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "83it [00:04, 17.04it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train loss: 0.7502924704257353\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "103it [00:06, 17.03it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train loss: 0.7493968558783578\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "123it [00:07, 17.02it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train loss: 0.7503062289608412\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "143it [00:08, 17.01it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train loss: 0.7499907469073086\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "163it [00:09, 17.01it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train loss: 0.7488915150209984\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "183it [00:10, 16.99it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train loss: 0.7494832198264191\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "203it [00:11, 17.03it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train loss: 0.7496299450077227\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "223it [00:13, 17.03it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train loss: 0.7498336488305174\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "225it [00:13, 16.93it/s]\n",
      "100%|█████████████████████████████████████████| 225/225 [00:09<00:00, 24.15it/s]\n",
      "100%|███████████████████████████████████████████| 61/61 [00:02<00:00, 22.79it/s]\n",
      "/mnt/disk2/ndubrovnyi/words_similarity/.venv/lib/python3.8/site-packages/sklearn/neighbors/_nearest_centroid.py:168: UserWarning: Averaging for metrics other than euclidean and manhattan not supported. The average is set to be the mean.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 10\n",
      "Train Loss: 0.7507081786791484\n",
      "ACC@3: 0.8855079938112429\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "3it [00:00, 14.21it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train loss: 0.6570945382118225\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "23it [00:01, 17.04it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train loss: 0.7338789474396479\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "43it [00:02, 17.06it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train loss: 0.7401644980035177\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "63it [00:03, 17.11it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train loss: 0.7384500210402442\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "83it [00:04, 17.01it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train loss: 0.7386416005499569\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "103it [00:06, 17.01it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train loss: 0.7387343279205927\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "123it [00:07, 17.00it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train loss: 0.7394577107153648\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "143it [00:08, 17.00it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train loss: 0.7386350141349414\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "163it [00:09, 16.98it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train loss: 0.7385702858800474\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "183it [00:10, 16.36it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train loss: 0.739099879949791\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "203it [00:12, 16.97it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train loss: 0.7391674524516015\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "223it [00:13, 17.00it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train loss: 0.7395437920794767\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "225it [00:13, 16.87it/s]\n",
      "100%|█████████████████████████████████████████| 225/225 [00:09<00:00, 24.05it/s]\n",
      "100%|███████████████████████████████████████████| 61/61 [00:02<00:00, 22.69it/s]\n",
      "/mnt/disk2/ndubrovnyi/words_similarity/.venv/lib/python3.8/site-packages/sklearn/neighbors/_nearest_centroid.py:168: UserWarning: Averaging for metrics other than euclidean and manhattan not supported. The average is set to be the mean.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 11\n",
      "Train Loss: 0.7398785161972046\n",
      "ACC@3: 0.8916967509025271\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "4it [00:00, 15.37it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train loss: 0.6917500495910645\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "24it [00:01, 17.01it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train loss: 0.7365348225548154\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "44it [00:02, 17.02it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train loss: 0.7403762282394781\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "64it [00:03, 17.03it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train loss: 0.7425942762953336\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "84it [00:04, 17.01it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train loss: 0.7405300574538148\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "104it [00:06, 16.99it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train loss: 0.739702837301953\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "124it [00:07, 16.95it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train loss: 0.7395813159706178\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "144it [00:08, 17.02it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train loss: 0.7381895476199211\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "164it [00:09, 17.02it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train loss: 0.7371026373798062\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "184it [00:10, 17.02it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train loss: 0.736076293070672\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "204it [00:12, 17.00it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train loss: 0.7362755821711982\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "224it [00:13, 17.00it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train loss: 0.7361793698768271\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "225it [00:13, 16.96it/s]\n",
      "100%|█████████████████████████████████████████| 225/225 [00:09<00:00, 24.05it/s]\n",
      "100%|███████████████████████████████████████████| 61/61 [00:02<00:00, 22.06it/s]\n",
      "/mnt/disk2/ndubrovnyi/words_similarity/.venv/lib/python3.8/site-packages/sklearn/neighbors/_nearest_centroid.py:168: UserWarning: Averaging for metrics other than euclidean and manhattan not supported. The average is set to be the mean.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 12\n",
      "Train Loss: 0.735728436311086\n",
      "ACC@3: 0.8973697782362042\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "4it [00:00, 14.73it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train loss: 0.7368567585945129\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "24it [00:01, 17.00it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train loss: 0.729854629153297\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "44it [00:02, 17.04it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train loss: 0.7286783892933916\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "64it [00:03, 17.05it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train loss: 0.7289489038655015\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "84it [00:04, 17.02it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train loss: 0.7304821271955231\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "104it [00:06, 17.01it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train loss: 0.7310854096223812\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "124it [00:07, 16.98it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train loss: 0.7318523092703386\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "144it [00:08, 16.97it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train loss: 0.7318875641687542\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "164it [00:09, 17.01it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train loss: 0.7329649114460679\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "184it [00:10, 17.01it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train loss: 0.7325169776684671\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "204it [00:12, 16.99it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train loss: 0.7334428474084654\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "224it [00:13, 17.03it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train loss: 0.7332476372093097\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "225it [00:13, 16.94it/s]\n",
      "100%|█████████████████████████████████████████| 225/225 [00:09<00:00, 24.18it/s]\n",
      "100%|███████████████████████████████████████████| 61/61 [00:02<00:00, 22.89it/s]\n",
      "/mnt/disk2/ndubrovnyi/words_similarity/.venv/lib/python3.8/site-packages/sklearn/neighbors/_nearest_centroid.py:168: UserWarning: Averaging for metrics other than euclidean and manhattan not supported. The average is set to be the mean.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 13\n",
      "Train Loss: 0.7333497566646999\n",
      "ACC@3: 0.9017534811758638\n",
      "feature_extractor.embeddings.word_embeddings.weight False\n",
      "feature_extractor.embeddings.position_embeddings.weight False\n",
      "feature_extractor.embeddings.token_type_embeddings.weight False\n",
      "feature_extractor.embeddings.LayerNorm.weight False\n",
      "feature_extractor.embeddings.LayerNorm.bias False\n",
      "feature_extractor.encoder.layer.0.attention.self.query.weight False\n",
      "feature_extractor.encoder.layer.0.attention.self.query.bias False\n",
      "feature_extractor.encoder.layer.0.attention.self.key.weight False\n",
      "feature_extractor.encoder.layer.0.attention.self.key.bias False\n",
      "feature_extractor.encoder.layer.0.attention.self.value.weight False\n",
      "feature_extractor.encoder.layer.0.attention.self.value.bias False\n",
      "feature_extractor.encoder.layer.0.attention.output.dense.weight False\n",
      "feature_extractor.encoder.layer.0.attention.output.dense.bias False\n",
      "feature_extractor.encoder.layer.0.attention.output.LayerNorm.weight False\n",
      "feature_extractor.encoder.layer.0.attention.output.LayerNorm.bias False\n",
      "feature_extractor.encoder.layer.0.intermediate.dense.weight False\n",
      "feature_extractor.encoder.layer.0.intermediate.dense.bias False\n",
      "feature_extractor.encoder.layer.0.output.dense.weight False\n",
      "feature_extractor.encoder.layer.0.output.dense.bias False\n",
      "feature_extractor.encoder.layer.0.output.LayerNorm.weight False\n",
      "feature_extractor.encoder.layer.0.output.LayerNorm.bias False\n",
      "feature_extractor.encoder.layer.1.attention.self.query.weight False\n",
      "feature_extractor.encoder.layer.1.attention.self.query.bias False\n",
      "feature_extractor.encoder.layer.1.attention.self.key.weight False\n",
      "feature_extractor.encoder.layer.1.attention.self.key.bias False\n",
      "feature_extractor.encoder.layer.1.attention.self.value.weight False\n",
      "feature_extractor.encoder.layer.1.attention.self.value.bias False\n",
      "feature_extractor.encoder.layer.1.attention.output.dense.weight False\n",
      "feature_extractor.encoder.layer.1.attention.output.dense.bias False\n",
      "feature_extractor.encoder.layer.1.attention.output.LayerNorm.weight False\n",
      "feature_extractor.encoder.layer.1.attention.output.LayerNorm.bias False\n",
      "feature_extractor.encoder.layer.1.intermediate.dense.weight False\n",
      "feature_extractor.encoder.layer.1.intermediate.dense.bias False\n",
      "feature_extractor.encoder.layer.1.output.dense.weight False\n",
      "feature_extractor.encoder.layer.1.output.dense.bias False\n",
      "feature_extractor.encoder.layer.1.output.LayerNorm.weight False\n",
      "feature_extractor.encoder.layer.1.output.LayerNorm.bias False\n",
      "feature_extractor.encoder.layer.2.attention.self.query.weight False\n",
      "feature_extractor.encoder.layer.2.attention.self.query.bias False\n",
      "feature_extractor.encoder.layer.2.attention.self.key.weight False\n",
      "feature_extractor.encoder.layer.2.attention.self.key.bias False\n",
      "feature_extractor.encoder.layer.2.attention.self.value.weight False\n",
      "feature_extractor.encoder.layer.2.attention.self.value.bias False\n",
      "feature_extractor.encoder.layer.2.attention.output.dense.weight False\n",
      "feature_extractor.encoder.layer.2.attention.output.dense.bias False\n",
      "feature_extractor.encoder.layer.2.attention.output.LayerNorm.weight False\n",
      "feature_extractor.encoder.layer.2.attention.output.LayerNorm.bias False\n",
      "feature_extractor.encoder.layer.2.intermediate.dense.weight False\n",
      "feature_extractor.encoder.layer.2.intermediate.dense.bias False\n",
      "feature_extractor.encoder.layer.2.output.dense.weight False\n",
      "feature_extractor.encoder.layer.2.output.dense.bias False\n",
      "feature_extractor.encoder.layer.2.output.LayerNorm.weight False\n",
      "feature_extractor.encoder.layer.2.output.LayerNorm.bias False\n",
      "feature_extractor.encoder.layer.3.attention.self.query.weight False\n",
      "feature_extractor.encoder.layer.3.attention.self.query.bias False\n",
      "feature_extractor.encoder.layer.3.attention.self.key.weight False\n",
      "feature_extractor.encoder.layer.3.attention.self.key.bias False\n",
      "feature_extractor.encoder.layer.3.attention.self.value.weight False\n",
      "feature_extractor.encoder.layer.3.attention.self.value.bias False\n",
      "feature_extractor.encoder.layer.3.attention.output.dense.weight False\n",
      "feature_extractor.encoder.layer.3.attention.output.dense.bias False\n",
      "feature_extractor.encoder.layer.3.attention.output.LayerNorm.weight False\n",
      "feature_extractor.encoder.layer.3.attention.output.LayerNorm.bias False\n",
      "feature_extractor.encoder.layer.3.intermediate.dense.weight False\n",
      "feature_extractor.encoder.layer.3.intermediate.dense.bias False\n",
      "feature_extractor.encoder.layer.3.output.dense.weight False\n",
      "feature_extractor.encoder.layer.3.output.dense.bias False\n",
      "feature_extractor.encoder.layer.3.output.LayerNorm.weight False\n",
      "feature_extractor.encoder.layer.3.output.LayerNorm.bias False\n",
      "feature_extractor.encoder.layer.4.attention.self.query.weight False\n",
      "feature_extractor.encoder.layer.4.attention.self.query.bias False\n",
      "feature_extractor.encoder.layer.4.attention.self.key.weight False\n",
      "feature_extractor.encoder.layer.4.attention.self.key.bias False\n",
      "feature_extractor.encoder.layer.4.attention.self.value.weight False\n",
      "feature_extractor.encoder.layer.4.attention.self.value.bias False\n",
      "feature_extractor.encoder.layer.4.attention.output.dense.weight False\n",
      "feature_extractor.encoder.layer.4.attention.output.dense.bias False\n",
      "feature_extractor.encoder.layer.4.attention.output.LayerNorm.weight False\n",
      "feature_extractor.encoder.layer.4.attention.output.LayerNorm.bias False\n",
      "feature_extractor.encoder.layer.4.intermediate.dense.weight False\n",
      "feature_extractor.encoder.layer.4.intermediate.dense.bias False\n",
      "feature_extractor.encoder.layer.4.output.dense.weight False\n",
      "feature_extractor.encoder.layer.4.output.dense.bias False\n",
      "feature_extractor.encoder.layer.4.output.LayerNorm.weight False\n",
      "feature_extractor.encoder.layer.4.output.LayerNorm.bias False\n",
      "feature_extractor.encoder.layer.5.attention.self.query.weight False\n",
      "feature_extractor.encoder.layer.5.attention.self.query.bias False\n",
      "feature_extractor.encoder.layer.5.attention.self.key.weight False\n",
      "feature_extractor.encoder.layer.5.attention.self.key.bias False\n",
      "feature_extractor.encoder.layer.5.attention.self.value.weight False\n",
      "feature_extractor.encoder.layer.5.attention.self.value.bias False\n",
      "feature_extractor.encoder.layer.5.attention.output.dense.weight False\n",
      "feature_extractor.encoder.layer.5.attention.output.dense.bias False\n",
      "feature_extractor.encoder.layer.5.attention.output.LayerNorm.weight False\n",
      "feature_extractor.encoder.layer.5.attention.output.LayerNorm.bias False\n",
      "feature_extractor.encoder.layer.5.intermediate.dense.weight False\n",
      "feature_extractor.encoder.layer.5.intermediate.dense.bias False\n",
      "feature_extractor.encoder.layer.5.output.dense.weight False\n",
      "feature_extractor.encoder.layer.5.output.dense.bias False\n",
      "feature_extractor.encoder.layer.5.output.LayerNorm.weight False\n",
      "feature_extractor.encoder.layer.5.output.LayerNorm.bias False\n",
      "feature_extractor.encoder.layer.6.attention.self.query.weight False\n",
      "feature_extractor.encoder.layer.6.attention.self.query.bias False\n",
      "feature_extractor.encoder.layer.6.attention.self.key.weight False\n",
      "feature_extractor.encoder.layer.6.attention.self.key.bias False\n",
      "feature_extractor.encoder.layer.6.attention.self.value.weight False\n",
      "feature_extractor.encoder.layer.6.attention.self.value.bias False\n",
      "feature_extractor.encoder.layer.6.attention.output.dense.weight False\n",
      "feature_extractor.encoder.layer.6.attention.output.dense.bias False\n",
      "feature_extractor.encoder.layer.6.attention.output.LayerNorm.weight False\n",
      "feature_extractor.encoder.layer.6.attention.output.LayerNorm.bias False\n",
      "feature_extractor.encoder.layer.6.intermediate.dense.weight False\n",
      "feature_extractor.encoder.layer.6.intermediate.dense.bias False\n",
      "feature_extractor.encoder.layer.6.output.dense.weight False\n",
      "feature_extractor.encoder.layer.6.output.dense.bias False\n",
      "feature_extractor.encoder.layer.6.output.LayerNorm.weight False\n",
      "feature_extractor.encoder.layer.6.output.LayerNorm.bias False\n",
      "feature_extractor.encoder.layer.7.attention.self.query.weight False\n",
      "feature_extractor.encoder.layer.7.attention.self.query.bias False\n",
      "feature_extractor.encoder.layer.7.attention.self.key.weight False\n",
      "feature_extractor.encoder.layer.7.attention.self.key.bias False\n",
      "feature_extractor.encoder.layer.7.attention.self.value.weight False\n",
      "feature_extractor.encoder.layer.7.attention.self.value.bias False\n",
      "feature_extractor.encoder.layer.7.attention.output.dense.weight False\n",
      "feature_extractor.encoder.layer.7.attention.output.dense.bias False\n",
      "feature_extractor.encoder.layer.7.attention.output.LayerNorm.weight False\n",
      "feature_extractor.encoder.layer.7.attention.output.LayerNorm.bias False\n",
      "feature_extractor.encoder.layer.7.intermediate.dense.weight False\n",
      "feature_extractor.encoder.layer.7.intermediate.dense.bias False\n",
      "feature_extractor.encoder.layer.7.output.dense.weight False\n",
      "feature_extractor.encoder.layer.7.output.dense.bias False\n",
      "feature_extractor.encoder.layer.7.output.LayerNorm.weight False\n",
      "feature_extractor.encoder.layer.7.output.LayerNorm.bias False\n",
      "feature_extractor.encoder.layer.8.attention.self.query.weight False\n",
      "feature_extractor.encoder.layer.8.attention.self.query.bias False\n",
      "feature_extractor.encoder.layer.8.attention.self.key.weight False\n",
      "feature_extractor.encoder.layer.8.attention.self.key.bias False\n",
      "feature_extractor.encoder.layer.8.attention.self.value.weight False\n",
      "feature_extractor.encoder.layer.8.attention.self.value.bias False\n",
      "feature_extractor.encoder.layer.8.attention.output.dense.weight False\n",
      "feature_extractor.encoder.layer.8.attention.output.dense.bias False\n",
      "feature_extractor.encoder.layer.8.attention.output.LayerNorm.weight False\n",
      "feature_extractor.encoder.layer.8.attention.output.LayerNorm.bias False\n",
      "feature_extractor.encoder.layer.8.intermediate.dense.weight False\n",
      "feature_extractor.encoder.layer.8.intermediate.dense.bias False\n",
      "feature_extractor.encoder.layer.8.output.dense.weight False\n",
      "feature_extractor.encoder.layer.8.output.dense.bias False\n",
      "feature_extractor.encoder.layer.8.output.LayerNorm.weight False\n",
      "feature_extractor.encoder.layer.8.output.LayerNorm.bias False\n",
      "feature_extractor.encoder.layer.9.attention.self.query.weight True\n",
      "feature_extractor.encoder.layer.9.attention.self.query.bias True\n",
      "feature_extractor.encoder.layer.9.attention.self.key.weight True\n",
      "feature_extractor.encoder.layer.9.attention.self.key.bias True\n",
      "feature_extractor.encoder.layer.9.attention.self.value.weight True\n",
      "feature_extractor.encoder.layer.9.attention.self.value.bias True\n",
      "feature_extractor.encoder.layer.9.attention.output.dense.weight True\n",
      "feature_extractor.encoder.layer.9.attention.output.dense.bias True\n",
      "feature_extractor.encoder.layer.9.attention.output.LayerNorm.weight True\n",
      "feature_extractor.encoder.layer.9.attention.output.LayerNorm.bias True\n",
      "feature_extractor.encoder.layer.9.intermediate.dense.weight True\n",
      "feature_extractor.encoder.layer.9.intermediate.dense.bias True\n",
      "feature_extractor.encoder.layer.9.output.dense.weight True\n",
      "feature_extractor.encoder.layer.9.output.dense.bias True\n",
      "feature_extractor.encoder.layer.9.output.LayerNorm.weight True\n",
      "feature_extractor.encoder.layer.9.output.LayerNorm.bias True\n",
      "feature_extractor.encoder.layer.10.attention.self.query.weight True\n",
      "feature_extractor.encoder.layer.10.attention.self.query.bias True\n",
      "feature_extractor.encoder.layer.10.attention.self.key.weight True\n",
      "feature_extractor.encoder.layer.10.attention.self.key.bias True\n",
      "feature_extractor.encoder.layer.10.attention.self.value.weight True\n",
      "feature_extractor.encoder.layer.10.attention.self.value.bias True\n",
      "feature_extractor.encoder.layer.10.attention.output.dense.weight True\n",
      "feature_extractor.encoder.layer.10.attention.output.dense.bias True\n",
      "feature_extractor.encoder.layer.10.attention.output.LayerNorm.weight True\n",
      "feature_extractor.encoder.layer.10.attention.output.LayerNorm.bias True\n",
      "feature_extractor.encoder.layer.10.intermediate.dense.weight True\n",
      "feature_extractor.encoder.layer.10.intermediate.dense.bias True\n",
      "feature_extractor.encoder.layer.10.output.dense.weight True\n",
      "feature_extractor.encoder.layer.10.output.dense.bias True\n",
      "feature_extractor.encoder.layer.10.output.LayerNorm.weight True\n",
      "feature_extractor.encoder.layer.10.output.LayerNorm.bias True\n",
      "feature_extractor.encoder.layer.11.attention.self.query.weight True\n",
      "feature_extractor.encoder.layer.11.attention.self.query.bias True\n",
      "feature_extractor.encoder.layer.11.attention.self.key.weight True\n",
      "feature_extractor.encoder.layer.11.attention.self.key.bias True\n",
      "feature_extractor.encoder.layer.11.attention.self.value.weight True\n",
      "feature_extractor.encoder.layer.11.attention.self.value.bias True\n",
      "feature_extractor.encoder.layer.11.attention.output.dense.weight True\n",
      "feature_extractor.encoder.layer.11.attention.output.dense.bias True\n",
      "feature_extractor.encoder.layer.11.attention.output.LayerNorm.weight True\n",
      "feature_extractor.encoder.layer.11.attention.output.LayerNorm.bias True\n",
      "feature_extractor.encoder.layer.11.intermediate.dense.weight True\n",
      "feature_extractor.encoder.layer.11.intermediate.dense.bias True\n",
      "feature_extractor.encoder.layer.11.output.dense.weight True\n",
      "feature_extractor.encoder.layer.11.output.dense.bias True\n",
      "feature_extractor.encoder.layer.11.output.LayerNorm.weight True\n",
      "feature_extractor.encoder.layer.11.output.LayerNorm.bias True\n",
      "feature_extractor.pooler.dense.weight True\n",
      "feature_extractor.pooler.dense.bias True\n",
      "head.weight True\n",
      "head.bias True\n",
      "arc.W True\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "3it [00:00, 12.15it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train loss: 0.7060862183570862\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "23it [00:01, 15.21it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train loss: 0.7357819137119112\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "43it [00:02, 15.26it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train loss: 0.733149223211335\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "63it [00:04, 15.24it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train loss: 0.7333111430777878\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "83it [00:05, 15.25it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train loss: 0.7326847278041604\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "103it [00:06, 15.19it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train loss: 0.7320069281181486\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "123it [00:08, 15.25it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train loss: 0.7333225666984053\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "143it [00:09, 15.23it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train loss: 0.7329937832575317\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "163it [00:10, 15.24it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train loss: 0.7332724429065396\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "183it [00:12, 15.26it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train loss: 0.7329891241716416\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "203it [00:13, 15.25it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train loss: 0.7322594665769321\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "223it [00:14, 15.26it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train loss: 0.7328096086083494\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "225it [00:14, 15.17it/s]\n",
      "100%|█████████████████████████████████████████| 225/225 [00:09<00:00, 23.89it/s]\n",
      "100%|███████████████████████████████████████████| 61/61 [00:02<00:00, 22.80it/s]\n",
      "/mnt/disk2/ndubrovnyi/words_similarity/.venv/lib/python3.8/site-packages/sklearn/neighbors/_nearest_centroid.py:168: UserWarning: Averaging for metrics other than euclidean and manhattan not supported. The average is set to be the mean.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 14\n",
      "Train Loss: 0.7328266090816922\n",
      "ACC@3: 0.9040742650850954\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "3it [00:00, 12.43it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train loss: 0.7167532444000244\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "23it [00:01, 15.22it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train loss: 0.7249513694218227\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "43it [00:02, 15.25it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train loss: 0.7235713063216791\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "63it [00:04, 15.26it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train loss: 0.7243831304253124\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "83it [00:05, 15.25it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train loss: 0.7253708780547719\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "103it [00:06, 15.25it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train loss: 0.7266873020936947\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "123it [00:08, 15.25it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train loss: 0.72688953393747\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "143it [00:09, 15.23it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train loss: 0.7281269951069609\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "163it [00:10, 15.25it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train loss: 0.7280620995515622\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "183it [00:12, 15.25it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train loss: 0.7286145631121008\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "203it [00:13, 15.24it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train loss: 0.7291582034001896\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "223it [00:14, 15.26it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train loss: 0.7291538515781385\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "225it [00:14, 15.18it/s]\n",
      "100%|█████████████████████████████████████████| 225/225 [00:09<00:00, 23.97it/s]\n",
      "100%|███████████████████████████████████████████| 61/61 [00:02<00:00, 22.74it/s]\n",
      "/mnt/disk2/ndubrovnyi/words_similarity/.venv/lib/python3.8/site-packages/sklearn/neighbors/_nearest_centroid.py:168: UserWarning: Averaging for metrics other than euclidean and manhattan not supported. The average is set to be the mean.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 15\n",
      "Train Loss: 0.7294321582052443\n",
      "ACC@3: 0.9048478597215059\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "3it [00:00, 12.99it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train loss: 0.7418766021728516\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "23it [00:01, 15.24it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train loss: 0.7253213240986779\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "43it [00:02, 15.24it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train loss: 0.7251260178845104\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "63it [00:04, 15.25it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train loss: 0.7255840975730146\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "83it [00:05, 15.27it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train loss: 0.7260379246723505\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "103it [00:06, 15.21it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train loss: 0.72585661812584\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "123it [00:08, 15.25it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train loss: 0.7254644474707359\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "143it [00:09, 15.23it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train loss: 0.7263387576908085\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "163it [00:10, 15.25it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train loss: 0.7262824944087437\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "183it [00:12, 15.25it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train loss: 0.7264081447163998\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "203it [00:13, 15.23it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train loss: 0.7260923999458996\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "223it [00:14, 15.22it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train loss: 0.726260104600121\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "225it [00:14, 15.20it/s]\n",
      "100%|█████████████████████████████████████████| 225/225 [00:09<00:00, 24.02it/s]\n",
      "100%|███████████████████████████████████████████| 61/61 [00:02<00:00, 22.45it/s]\n",
      "/mnt/disk2/ndubrovnyi/words_similarity/.venv/lib/python3.8/site-packages/sklearn/neighbors/_nearest_centroid.py:168: UserWarning: Averaging for metrics other than euclidean and manhattan not supported. The average is set to be the mean.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 16\n",
      "Train Loss: 0.7262115642759535\n",
      "ACC@3: 0.907942238267148\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "3it [00:00, 12.98it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train loss: 0.7068858742713928\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "23it [00:01, 15.25it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train loss: 0.7276476252646673\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "43it [00:02, 15.28it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train loss: 0.7242973577685472\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "63it [00:04, 15.11it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train loss: 0.7236153590874593\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "83it [00:05, 15.23it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train loss: 0.7233766780959235\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "103it [00:06, 15.23it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train loss: 0.7235314981772167\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "123it [00:08, 15.24it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train loss: 0.72360875783873\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "143it [00:09, 15.23it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train loss: 0.7234837476243364\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "163it [00:10, 15.21it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train loss: 0.7239999856267657\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "183it [00:12, 15.23it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train loss: 0.7246825013371462\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "203it [00:13, 15.20it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train loss: 0.7243476370673868\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "223it [00:14, 15.23it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train loss: 0.7244482013434846\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "225it [00:14, 15.15it/s]\n",
      "100%|█████████████████████████████████████████| 225/225 [00:09<00:00, 23.98it/s]\n",
      "100%|███████████████████████████████████████████| 61/61 [00:02<00:00, 22.26it/s]\n",
      "/mnt/disk2/ndubrovnyi/words_similarity/.venv/lib/python3.8/site-packages/sklearn/neighbors/_nearest_centroid.py:168: UserWarning: Averaging for metrics other than euclidean and manhattan not supported. The average is set to be the mean.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 17\n",
      "Train Loss: 0.7242878847652011\n",
      "ACC@3: 0.910005157297576\n",
      "feature_extractor.embeddings.word_embeddings.weight False\n",
      "feature_extractor.embeddings.position_embeddings.weight False\n",
      "feature_extractor.embeddings.token_type_embeddings.weight False\n",
      "feature_extractor.embeddings.LayerNorm.weight False\n",
      "feature_extractor.embeddings.LayerNorm.bias False\n",
      "feature_extractor.encoder.layer.0.attention.self.query.weight False\n",
      "feature_extractor.encoder.layer.0.attention.self.query.bias False\n",
      "feature_extractor.encoder.layer.0.attention.self.key.weight False\n",
      "feature_extractor.encoder.layer.0.attention.self.key.bias False\n",
      "feature_extractor.encoder.layer.0.attention.self.value.weight False\n",
      "feature_extractor.encoder.layer.0.attention.self.value.bias False\n",
      "feature_extractor.encoder.layer.0.attention.output.dense.weight False\n",
      "feature_extractor.encoder.layer.0.attention.output.dense.bias False\n",
      "feature_extractor.encoder.layer.0.attention.output.LayerNorm.weight False\n",
      "feature_extractor.encoder.layer.0.attention.output.LayerNorm.bias False\n",
      "feature_extractor.encoder.layer.0.intermediate.dense.weight False\n",
      "feature_extractor.encoder.layer.0.intermediate.dense.bias False\n",
      "feature_extractor.encoder.layer.0.output.dense.weight False\n",
      "feature_extractor.encoder.layer.0.output.dense.bias False\n",
      "feature_extractor.encoder.layer.0.output.LayerNorm.weight False\n",
      "feature_extractor.encoder.layer.0.output.LayerNorm.bias False\n",
      "feature_extractor.encoder.layer.1.attention.self.query.weight False\n",
      "feature_extractor.encoder.layer.1.attention.self.query.bias False\n",
      "feature_extractor.encoder.layer.1.attention.self.key.weight False\n",
      "feature_extractor.encoder.layer.1.attention.self.key.bias False\n",
      "feature_extractor.encoder.layer.1.attention.self.value.weight False\n",
      "feature_extractor.encoder.layer.1.attention.self.value.bias False\n",
      "feature_extractor.encoder.layer.1.attention.output.dense.weight False\n",
      "feature_extractor.encoder.layer.1.attention.output.dense.bias False\n",
      "feature_extractor.encoder.layer.1.attention.output.LayerNorm.weight False\n",
      "feature_extractor.encoder.layer.1.attention.output.LayerNorm.bias False\n",
      "feature_extractor.encoder.layer.1.intermediate.dense.weight False\n",
      "feature_extractor.encoder.layer.1.intermediate.dense.bias False\n",
      "feature_extractor.encoder.layer.1.output.dense.weight False\n",
      "feature_extractor.encoder.layer.1.output.dense.bias False\n",
      "feature_extractor.encoder.layer.1.output.LayerNorm.weight False\n",
      "feature_extractor.encoder.layer.1.output.LayerNorm.bias False\n",
      "feature_extractor.encoder.layer.2.attention.self.query.weight False\n",
      "feature_extractor.encoder.layer.2.attention.self.query.bias False\n",
      "feature_extractor.encoder.layer.2.attention.self.key.weight False\n",
      "feature_extractor.encoder.layer.2.attention.self.key.bias False\n",
      "feature_extractor.encoder.layer.2.attention.self.value.weight False\n",
      "feature_extractor.encoder.layer.2.attention.self.value.bias False\n",
      "feature_extractor.encoder.layer.2.attention.output.dense.weight False\n",
      "feature_extractor.encoder.layer.2.attention.output.dense.bias False\n",
      "feature_extractor.encoder.layer.2.attention.output.LayerNorm.weight False\n",
      "feature_extractor.encoder.layer.2.attention.output.LayerNorm.bias False\n",
      "feature_extractor.encoder.layer.2.intermediate.dense.weight False\n",
      "feature_extractor.encoder.layer.2.intermediate.dense.bias False\n",
      "feature_extractor.encoder.layer.2.output.dense.weight False\n",
      "feature_extractor.encoder.layer.2.output.dense.bias False\n",
      "feature_extractor.encoder.layer.2.output.LayerNorm.weight False\n",
      "feature_extractor.encoder.layer.2.output.LayerNorm.bias False\n",
      "feature_extractor.encoder.layer.3.attention.self.query.weight False\n",
      "feature_extractor.encoder.layer.3.attention.self.query.bias False\n",
      "feature_extractor.encoder.layer.3.attention.self.key.weight False\n",
      "feature_extractor.encoder.layer.3.attention.self.key.bias False\n",
      "feature_extractor.encoder.layer.3.attention.self.value.weight False\n",
      "feature_extractor.encoder.layer.3.attention.self.value.bias False\n",
      "feature_extractor.encoder.layer.3.attention.output.dense.weight False\n",
      "feature_extractor.encoder.layer.3.attention.output.dense.bias False\n",
      "feature_extractor.encoder.layer.3.attention.output.LayerNorm.weight False\n",
      "feature_extractor.encoder.layer.3.attention.output.LayerNorm.bias False\n",
      "feature_extractor.encoder.layer.3.intermediate.dense.weight False\n",
      "feature_extractor.encoder.layer.3.intermediate.dense.bias False\n",
      "feature_extractor.encoder.layer.3.output.dense.weight False\n",
      "feature_extractor.encoder.layer.3.output.dense.bias False\n",
      "feature_extractor.encoder.layer.3.output.LayerNorm.weight False\n",
      "feature_extractor.encoder.layer.3.output.LayerNorm.bias False\n",
      "feature_extractor.encoder.layer.4.attention.self.query.weight False\n",
      "feature_extractor.encoder.layer.4.attention.self.query.bias False\n",
      "feature_extractor.encoder.layer.4.attention.self.key.weight False\n",
      "feature_extractor.encoder.layer.4.attention.self.key.bias False\n",
      "feature_extractor.encoder.layer.4.attention.self.value.weight False\n",
      "feature_extractor.encoder.layer.4.attention.self.value.bias False\n",
      "feature_extractor.encoder.layer.4.attention.output.dense.weight False\n",
      "feature_extractor.encoder.layer.4.attention.output.dense.bias False\n",
      "feature_extractor.encoder.layer.4.attention.output.LayerNorm.weight False\n",
      "feature_extractor.encoder.layer.4.attention.output.LayerNorm.bias False\n",
      "feature_extractor.encoder.layer.4.intermediate.dense.weight False\n",
      "feature_extractor.encoder.layer.4.intermediate.dense.bias False\n",
      "feature_extractor.encoder.layer.4.output.dense.weight False\n",
      "feature_extractor.encoder.layer.4.output.dense.bias False\n",
      "feature_extractor.encoder.layer.4.output.LayerNorm.weight False\n",
      "feature_extractor.encoder.layer.4.output.LayerNorm.bias False\n",
      "feature_extractor.encoder.layer.5.attention.self.query.weight False\n",
      "feature_extractor.encoder.layer.5.attention.self.query.bias False\n",
      "feature_extractor.encoder.layer.5.attention.self.key.weight False\n",
      "feature_extractor.encoder.layer.5.attention.self.key.bias False\n",
      "feature_extractor.encoder.layer.5.attention.self.value.weight False\n",
      "feature_extractor.encoder.layer.5.attention.self.value.bias False\n",
      "feature_extractor.encoder.layer.5.attention.output.dense.weight False\n",
      "feature_extractor.encoder.layer.5.attention.output.dense.bias False\n",
      "feature_extractor.encoder.layer.5.attention.output.LayerNorm.weight False\n",
      "feature_extractor.encoder.layer.5.attention.output.LayerNorm.bias False\n",
      "feature_extractor.encoder.layer.5.intermediate.dense.weight False\n",
      "feature_extractor.encoder.layer.5.intermediate.dense.bias False\n",
      "feature_extractor.encoder.layer.5.output.dense.weight False\n",
      "feature_extractor.encoder.layer.5.output.dense.bias False\n",
      "feature_extractor.encoder.layer.5.output.LayerNorm.weight False\n",
      "feature_extractor.encoder.layer.5.output.LayerNorm.bias False\n",
      "feature_extractor.encoder.layer.6.attention.self.query.weight False\n",
      "feature_extractor.encoder.layer.6.attention.self.query.bias False\n",
      "feature_extractor.encoder.layer.6.attention.self.key.weight False\n",
      "feature_extractor.encoder.layer.6.attention.self.key.bias False\n",
      "feature_extractor.encoder.layer.6.attention.self.value.weight False\n",
      "feature_extractor.encoder.layer.6.attention.self.value.bias False\n",
      "feature_extractor.encoder.layer.6.attention.output.dense.weight False\n",
      "feature_extractor.encoder.layer.6.attention.output.dense.bias False\n",
      "feature_extractor.encoder.layer.6.attention.output.LayerNorm.weight False\n",
      "feature_extractor.encoder.layer.6.attention.output.LayerNorm.bias False\n",
      "feature_extractor.encoder.layer.6.intermediate.dense.weight False\n",
      "feature_extractor.encoder.layer.6.intermediate.dense.bias False\n",
      "feature_extractor.encoder.layer.6.output.dense.weight False\n",
      "feature_extractor.encoder.layer.6.output.dense.bias False\n",
      "feature_extractor.encoder.layer.6.output.LayerNorm.weight False\n",
      "feature_extractor.encoder.layer.6.output.LayerNorm.bias False\n",
      "feature_extractor.encoder.layer.7.attention.self.query.weight False\n",
      "feature_extractor.encoder.layer.7.attention.self.query.bias False\n",
      "feature_extractor.encoder.layer.7.attention.self.key.weight False\n",
      "feature_extractor.encoder.layer.7.attention.self.key.bias False\n",
      "feature_extractor.encoder.layer.7.attention.self.value.weight False\n",
      "feature_extractor.encoder.layer.7.attention.self.value.bias False\n",
      "feature_extractor.encoder.layer.7.attention.output.dense.weight False\n",
      "feature_extractor.encoder.layer.7.attention.output.dense.bias False\n",
      "feature_extractor.encoder.layer.7.attention.output.LayerNorm.weight False\n",
      "feature_extractor.encoder.layer.7.attention.output.LayerNorm.bias False\n",
      "feature_extractor.encoder.layer.7.intermediate.dense.weight False\n",
      "feature_extractor.encoder.layer.7.intermediate.dense.bias False\n",
      "feature_extractor.encoder.layer.7.output.dense.weight False\n",
      "feature_extractor.encoder.layer.7.output.dense.bias False\n",
      "feature_extractor.encoder.layer.7.output.LayerNorm.weight False\n",
      "feature_extractor.encoder.layer.7.output.LayerNorm.bias False\n",
      "feature_extractor.encoder.layer.8.attention.self.query.weight True\n",
      "feature_extractor.encoder.layer.8.attention.self.query.bias True\n",
      "feature_extractor.encoder.layer.8.attention.self.key.weight True\n",
      "feature_extractor.encoder.layer.8.attention.self.key.bias True\n",
      "feature_extractor.encoder.layer.8.attention.self.value.weight True\n",
      "feature_extractor.encoder.layer.8.attention.self.value.bias True\n",
      "feature_extractor.encoder.layer.8.attention.output.dense.weight True\n",
      "feature_extractor.encoder.layer.8.attention.output.dense.bias True\n",
      "feature_extractor.encoder.layer.8.attention.output.LayerNorm.weight True\n",
      "feature_extractor.encoder.layer.8.attention.output.LayerNorm.bias True\n",
      "feature_extractor.encoder.layer.8.intermediate.dense.weight True\n",
      "feature_extractor.encoder.layer.8.intermediate.dense.bias True\n",
      "feature_extractor.encoder.layer.8.output.dense.weight True\n",
      "feature_extractor.encoder.layer.8.output.dense.bias True\n",
      "feature_extractor.encoder.layer.8.output.LayerNorm.weight True\n",
      "feature_extractor.encoder.layer.8.output.LayerNorm.bias True\n",
      "feature_extractor.encoder.layer.9.attention.self.query.weight True\n",
      "feature_extractor.encoder.layer.9.attention.self.query.bias True\n",
      "feature_extractor.encoder.layer.9.attention.self.key.weight True\n",
      "feature_extractor.encoder.layer.9.attention.self.key.bias True\n",
      "feature_extractor.encoder.layer.9.attention.self.value.weight True\n",
      "feature_extractor.encoder.layer.9.attention.self.value.bias True\n",
      "feature_extractor.encoder.layer.9.attention.output.dense.weight True\n",
      "feature_extractor.encoder.layer.9.attention.output.dense.bias True\n",
      "feature_extractor.encoder.layer.9.attention.output.LayerNorm.weight True\n",
      "feature_extractor.encoder.layer.9.attention.output.LayerNorm.bias True\n",
      "feature_extractor.encoder.layer.9.intermediate.dense.weight True\n",
      "feature_extractor.encoder.layer.9.intermediate.dense.bias True\n",
      "feature_extractor.encoder.layer.9.output.dense.weight True\n",
      "feature_extractor.encoder.layer.9.output.dense.bias True\n",
      "feature_extractor.encoder.layer.9.output.LayerNorm.weight True\n",
      "feature_extractor.encoder.layer.9.output.LayerNorm.bias True\n",
      "feature_extractor.encoder.layer.10.attention.self.query.weight True\n",
      "feature_extractor.encoder.layer.10.attention.self.query.bias True\n",
      "feature_extractor.encoder.layer.10.attention.self.key.weight True\n",
      "feature_extractor.encoder.layer.10.attention.self.key.bias True\n",
      "feature_extractor.encoder.layer.10.attention.self.value.weight True\n",
      "feature_extractor.encoder.layer.10.attention.self.value.bias True\n",
      "feature_extractor.encoder.layer.10.attention.output.dense.weight True\n",
      "feature_extractor.encoder.layer.10.attention.output.dense.bias True\n",
      "feature_extractor.encoder.layer.10.attention.output.LayerNorm.weight True\n",
      "feature_extractor.encoder.layer.10.attention.output.LayerNorm.bias True\n",
      "feature_extractor.encoder.layer.10.intermediate.dense.weight True\n",
      "feature_extractor.encoder.layer.10.intermediate.dense.bias True\n",
      "feature_extractor.encoder.layer.10.output.dense.weight True\n",
      "feature_extractor.encoder.layer.10.output.dense.bias True\n",
      "feature_extractor.encoder.layer.10.output.LayerNorm.weight True\n",
      "feature_extractor.encoder.layer.10.output.LayerNorm.bias True\n",
      "feature_extractor.encoder.layer.11.attention.self.query.weight True\n",
      "feature_extractor.encoder.layer.11.attention.self.query.bias True\n",
      "feature_extractor.encoder.layer.11.attention.self.key.weight True\n",
      "feature_extractor.encoder.layer.11.attention.self.key.bias True\n",
      "feature_extractor.encoder.layer.11.attention.self.value.weight True\n",
      "feature_extractor.encoder.layer.11.attention.self.value.bias True\n",
      "feature_extractor.encoder.layer.11.attention.output.dense.weight True\n",
      "feature_extractor.encoder.layer.11.attention.output.dense.bias True\n",
      "feature_extractor.encoder.layer.11.attention.output.LayerNorm.weight True\n",
      "feature_extractor.encoder.layer.11.attention.output.LayerNorm.bias True\n",
      "feature_extractor.encoder.layer.11.intermediate.dense.weight True\n",
      "feature_extractor.encoder.layer.11.intermediate.dense.bias True\n",
      "feature_extractor.encoder.layer.11.output.dense.weight True\n",
      "feature_extractor.encoder.layer.11.output.dense.bias True\n",
      "feature_extractor.encoder.layer.11.output.LayerNorm.weight True\n",
      "feature_extractor.encoder.layer.11.output.LayerNorm.bias True\n",
      "feature_extractor.pooler.dense.weight True\n",
      "feature_extractor.pooler.dense.bias True\n",
      "head.weight True\n",
      "head.bias True\n",
      "arc.W True\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "3it [00:00, 11.34it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train loss: 0.704749584197998\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "23it [00:01, 13.81it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train loss: 0.7182409536270868\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "43it [00:03, 13.83it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train loss: 0.7194139274155221\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "63it [00:04, 13.85it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train loss: 0.7212235282679074\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "83it [00:06, 13.79it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train loss: 0.7201772552949411\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "103it [00:07, 13.83it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train loss: 0.720831316296417\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "123it [00:08, 13.83it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train loss: 0.7208238785917108\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "143it [00:10, 13.83it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train loss: 0.7205996001865846\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "163it [00:11, 13.81it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train loss: 0.7214205879602373\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "183it [00:13, 13.82it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train loss: 0.7221316761074804\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "203it [00:14, 13.79it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train loss: 0.7222588824395516\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "223it [00:16, 13.82it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train loss: 0.7224953711302572\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "225it [00:16, 13.76it/s]\n",
      "100%|█████████████████████████████████████████| 225/225 [00:09<00:00, 24.22it/s]\n",
      "100%|███████████████████████████████████████████| 61/61 [00:02<00:00, 22.63it/s]\n",
      "/mnt/disk2/ndubrovnyi/words_similarity/.venv/lib/python3.8/site-packages/sklearn/neighbors/_nearest_centroid.py:168: UserWarning: Averaging for metrics other than euclidean and manhattan not supported. The average is set to be the mean.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 18\n",
      "Train Loss: 0.7227293223804898\n",
      "ACC@3: 0.9115523465703971\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "3it [00:00, 12.02it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train loss: 0.7134315371513367\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "23it [00:01, 13.81it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train loss: 0.721696620895749\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "43it [00:03, 13.82it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train loss: 0.7191838273187963\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "63it [00:04, 13.81it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train loss: 0.720201241188362\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "83it [00:06, 13.81it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train loss: 0.7202233296853525\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "103it [00:07, 13.83it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train loss: 0.72048685987397\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "123it [00:08, 13.83it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train loss: 0.7204606927130833\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "143it [00:10, 13.80it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train loss: 0.7208110195525149\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "163it [00:11, 13.82it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train loss: 0.720884262775042\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "183it [00:13, 13.82it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train loss: 0.7207566967326633\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "203it [00:14, 13.82it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train loss: 0.720785985242075\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "223it [00:16, 13.79it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train loss: 0.7211561998630541\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "225it [00:16, 13.75it/s]\n",
      "100%|█████████████████████████████████████████| 225/225 [00:09<00:00, 24.06it/s]\n",
      "100%|███████████████████████████████████████████| 61/61 [00:02<00:00, 22.87it/s]\n",
      "/mnt/disk2/ndubrovnyi/words_similarity/.venv/lib/python3.8/site-packages/sklearn/neighbors/_nearest_centroid.py:168: UserWarning: Averaging for metrics other than euclidean and manhattan not supported. The average is set to be the mean.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 19\n",
      "Train Loss: 0.7211909363004896\n",
      "ACC@3: 0.9125838060856112\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "3it [00:00, 11.34it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train loss: 0.7254760265350342\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "23it [00:01, 13.77it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train loss: 0.7163354044868833\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "43it [00:03, 13.83it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train loss: 0.7162292396149984\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "63it [00:04, 13.82it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train loss: 0.7182841457304407\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "83it [00:06, 13.82it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train loss: 0.7194183027302777\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "103it [00:07, 13.81it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train loss: 0.7192538652089563\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "123it [00:08, 13.82it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train loss: 0.7187425898126334\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "143it [00:10, 13.78it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train loss: 0.7187758354430503\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "163it [00:11, 13.83it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train loss: 0.7190935441425869\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "183it [00:13, 13.83it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train loss: 0.7194098128798259\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "203it [00:14, 13.80it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train loss: 0.7197039234104441\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "223it [00:16, 13.82it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train loss: 0.7198187215295853\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "225it [00:16, 13.76it/s]\n",
      "100%|█████████████████████████████████████████| 225/225 [00:09<00:00, 24.02it/s]\n",
      "100%|███████████████████████████████████████████| 61/61 [00:02<00:00, 22.82it/s]\n",
      "/mnt/disk2/ndubrovnyi/words_similarity/.venv/lib/python3.8/site-packages/sklearn/neighbors/_nearest_centroid.py:168: UserWarning: Averaging for metrics other than euclidean and manhattan not supported. The average is set to be the mean.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 20\n",
      "Train Loss: 0.7197804482777913\n",
      "ACC@3: 0.9128416709644146\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "3it [00:00, 11.32it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train loss: 0.7150358557701111\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "23it [00:01, 13.79it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train loss: 0.7188473116783869\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "43it [00:03, 13.85it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train loss: 0.7181814647302395\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "63it [00:04, 13.81it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train loss: 0.7164302409672346\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "83it [00:06, 13.83it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train loss: 0.7172916193067291\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "103it [00:07, 13.84it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train loss: 0.7169343073769371\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "123it [00:08, 13.81it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train loss: 0.7170397934834819\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "143it [00:10, 13.85it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train loss: 0.7165852954201665\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "163it [00:11, 13.79it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train loss: 0.717014489706999\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "183it [00:13, 13.82it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train loss: 0.7168400498384929\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "203it [00:14, 13.81it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train loss: 0.7170755400586484\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "223it [00:16, 12.86it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train loss: 0.7174468463902021\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "225it [00:16, 13.72it/s]\n",
      "100%|█████████████████████████████████████████| 225/225 [00:09<00:00, 24.11it/s]\n",
      "100%|███████████████████████████████████████████| 61/61 [00:02<00:00, 22.47it/s]\n",
      "/mnt/disk2/ndubrovnyi/words_similarity/.venv/lib/python3.8/site-packages/sklearn/neighbors/_nearest_centroid.py:168: UserWarning: Averaging for metrics other than euclidean and manhattan not supported. The average is set to be the mean.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 21\n",
      "Train Loss: 0.7182034169303047\n",
      "ACC@3: 0.9128416709644146\n",
      "feature_extractor.embeddings.word_embeddings.weight False\n",
      "feature_extractor.embeddings.position_embeddings.weight False\n",
      "feature_extractor.embeddings.token_type_embeddings.weight False\n",
      "feature_extractor.embeddings.LayerNorm.weight False\n",
      "feature_extractor.embeddings.LayerNorm.bias False\n",
      "feature_extractor.encoder.layer.0.attention.self.query.weight False\n",
      "feature_extractor.encoder.layer.0.attention.self.query.bias False\n",
      "feature_extractor.encoder.layer.0.attention.self.key.weight False\n",
      "feature_extractor.encoder.layer.0.attention.self.key.bias False\n",
      "feature_extractor.encoder.layer.0.attention.self.value.weight False\n",
      "feature_extractor.encoder.layer.0.attention.self.value.bias False\n",
      "feature_extractor.encoder.layer.0.attention.output.dense.weight False\n",
      "feature_extractor.encoder.layer.0.attention.output.dense.bias False\n",
      "feature_extractor.encoder.layer.0.attention.output.LayerNorm.weight False\n",
      "feature_extractor.encoder.layer.0.attention.output.LayerNorm.bias False\n",
      "feature_extractor.encoder.layer.0.intermediate.dense.weight False\n",
      "feature_extractor.encoder.layer.0.intermediate.dense.bias False\n",
      "feature_extractor.encoder.layer.0.output.dense.weight False\n",
      "feature_extractor.encoder.layer.0.output.dense.bias False\n",
      "feature_extractor.encoder.layer.0.output.LayerNorm.weight False\n",
      "feature_extractor.encoder.layer.0.output.LayerNorm.bias False\n",
      "feature_extractor.encoder.layer.1.attention.self.query.weight False\n",
      "feature_extractor.encoder.layer.1.attention.self.query.bias False\n",
      "feature_extractor.encoder.layer.1.attention.self.key.weight False\n",
      "feature_extractor.encoder.layer.1.attention.self.key.bias False\n",
      "feature_extractor.encoder.layer.1.attention.self.value.weight False\n",
      "feature_extractor.encoder.layer.1.attention.self.value.bias False\n",
      "feature_extractor.encoder.layer.1.attention.output.dense.weight False\n",
      "feature_extractor.encoder.layer.1.attention.output.dense.bias False\n",
      "feature_extractor.encoder.layer.1.attention.output.LayerNorm.weight False\n",
      "feature_extractor.encoder.layer.1.attention.output.LayerNorm.bias False\n",
      "feature_extractor.encoder.layer.1.intermediate.dense.weight False\n",
      "feature_extractor.encoder.layer.1.intermediate.dense.bias False\n",
      "feature_extractor.encoder.layer.1.output.dense.weight False\n",
      "feature_extractor.encoder.layer.1.output.dense.bias False\n",
      "feature_extractor.encoder.layer.1.output.LayerNorm.weight False\n",
      "feature_extractor.encoder.layer.1.output.LayerNorm.bias False\n",
      "feature_extractor.encoder.layer.2.attention.self.query.weight False\n",
      "feature_extractor.encoder.layer.2.attention.self.query.bias False\n",
      "feature_extractor.encoder.layer.2.attention.self.key.weight False\n",
      "feature_extractor.encoder.layer.2.attention.self.key.bias False\n",
      "feature_extractor.encoder.layer.2.attention.self.value.weight False\n",
      "feature_extractor.encoder.layer.2.attention.self.value.bias False\n",
      "feature_extractor.encoder.layer.2.attention.output.dense.weight False\n",
      "feature_extractor.encoder.layer.2.attention.output.dense.bias False\n",
      "feature_extractor.encoder.layer.2.attention.output.LayerNorm.weight False\n",
      "feature_extractor.encoder.layer.2.attention.output.LayerNorm.bias False\n",
      "feature_extractor.encoder.layer.2.intermediate.dense.weight False\n",
      "feature_extractor.encoder.layer.2.intermediate.dense.bias False\n",
      "feature_extractor.encoder.layer.2.output.dense.weight False\n",
      "feature_extractor.encoder.layer.2.output.dense.bias False\n",
      "feature_extractor.encoder.layer.2.output.LayerNorm.weight False\n",
      "feature_extractor.encoder.layer.2.output.LayerNorm.bias False\n",
      "feature_extractor.encoder.layer.3.attention.self.query.weight False\n",
      "feature_extractor.encoder.layer.3.attention.self.query.bias False\n",
      "feature_extractor.encoder.layer.3.attention.self.key.weight False\n",
      "feature_extractor.encoder.layer.3.attention.self.key.bias False\n",
      "feature_extractor.encoder.layer.3.attention.self.value.weight False\n",
      "feature_extractor.encoder.layer.3.attention.self.value.bias False\n",
      "feature_extractor.encoder.layer.3.attention.output.dense.weight False\n",
      "feature_extractor.encoder.layer.3.attention.output.dense.bias False\n",
      "feature_extractor.encoder.layer.3.attention.output.LayerNorm.weight False\n",
      "feature_extractor.encoder.layer.3.attention.output.LayerNorm.bias False\n",
      "feature_extractor.encoder.layer.3.intermediate.dense.weight False\n",
      "feature_extractor.encoder.layer.3.intermediate.dense.bias False\n",
      "feature_extractor.encoder.layer.3.output.dense.weight False\n",
      "feature_extractor.encoder.layer.3.output.dense.bias False\n",
      "feature_extractor.encoder.layer.3.output.LayerNorm.weight False\n",
      "feature_extractor.encoder.layer.3.output.LayerNorm.bias False\n",
      "feature_extractor.encoder.layer.4.attention.self.query.weight False\n",
      "feature_extractor.encoder.layer.4.attention.self.query.bias False\n",
      "feature_extractor.encoder.layer.4.attention.self.key.weight False\n",
      "feature_extractor.encoder.layer.4.attention.self.key.bias False\n",
      "feature_extractor.encoder.layer.4.attention.self.value.weight False\n",
      "feature_extractor.encoder.layer.4.attention.self.value.bias False\n",
      "feature_extractor.encoder.layer.4.attention.output.dense.weight False\n",
      "feature_extractor.encoder.layer.4.attention.output.dense.bias False\n",
      "feature_extractor.encoder.layer.4.attention.output.LayerNorm.weight False\n",
      "feature_extractor.encoder.layer.4.attention.output.LayerNorm.bias False\n",
      "feature_extractor.encoder.layer.4.intermediate.dense.weight False\n",
      "feature_extractor.encoder.layer.4.intermediate.dense.bias False\n",
      "feature_extractor.encoder.layer.4.output.dense.weight False\n",
      "feature_extractor.encoder.layer.4.output.dense.bias False\n",
      "feature_extractor.encoder.layer.4.output.LayerNorm.weight False\n",
      "feature_extractor.encoder.layer.4.output.LayerNorm.bias False\n",
      "feature_extractor.encoder.layer.5.attention.self.query.weight False\n",
      "feature_extractor.encoder.layer.5.attention.self.query.bias False\n",
      "feature_extractor.encoder.layer.5.attention.self.key.weight False\n",
      "feature_extractor.encoder.layer.5.attention.self.key.bias False\n",
      "feature_extractor.encoder.layer.5.attention.self.value.weight False\n",
      "feature_extractor.encoder.layer.5.attention.self.value.bias False\n",
      "feature_extractor.encoder.layer.5.attention.output.dense.weight False\n",
      "feature_extractor.encoder.layer.5.attention.output.dense.bias False\n",
      "feature_extractor.encoder.layer.5.attention.output.LayerNorm.weight False\n",
      "feature_extractor.encoder.layer.5.attention.output.LayerNorm.bias False\n",
      "feature_extractor.encoder.layer.5.intermediate.dense.weight False\n",
      "feature_extractor.encoder.layer.5.intermediate.dense.bias False\n",
      "feature_extractor.encoder.layer.5.output.dense.weight False\n",
      "feature_extractor.encoder.layer.5.output.dense.bias False\n",
      "feature_extractor.encoder.layer.5.output.LayerNorm.weight False\n",
      "feature_extractor.encoder.layer.5.output.LayerNorm.bias False\n",
      "feature_extractor.encoder.layer.6.attention.self.query.weight False\n",
      "feature_extractor.encoder.layer.6.attention.self.query.bias False\n",
      "feature_extractor.encoder.layer.6.attention.self.key.weight False\n",
      "feature_extractor.encoder.layer.6.attention.self.key.bias False\n",
      "feature_extractor.encoder.layer.6.attention.self.value.weight False\n",
      "feature_extractor.encoder.layer.6.attention.self.value.bias False\n",
      "feature_extractor.encoder.layer.6.attention.output.dense.weight False\n",
      "feature_extractor.encoder.layer.6.attention.output.dense.bias False\n",
      "feature_extractor.encoder.layer.6.attention.output.LayerNorm.weight False\n",
      "feature_extractor.encoder.layer.6.attention.output.LayerNorm.bias False\n",
      "feature_extractor.encoder.layer.6.intermediate.dense.weight False\n",
      "feature_extractor.encoder.layer.6.intermediate.dense.bias False\n",
      "feature_extractor.encoder.layer.6.output.dense.weight False\n",
      "feature_extractor.encoder.layer.6.output.dense.bias False\n",
      "feature_extractor.encoder.layer.6.output.LayerNorm.weight False\n",
      "feature_extractor.encoder.layer.6.output.LayerNorm.bias False\n",
      "feature_extractor.encoder.layer.7.attention.self.query.weight True\n",
      "feature_extractor.encoder.layer.7.attention.self.query.bias True\n",
      "feature_extractor.encoder.layer.7.attention.self.key.weight True\n",
      "feature_extractor.encoder.layer.7.attention.self.key.bias True\n",
      "feature_extractor.encoder.layer.7.attention.self.value.weight True\n",
      "feature_extractor.encoder.layer.7.attention.self.value.bias True\n",
      "feature_extractor.encoder.layer.7.attention.output.dense.weight True\n",
      "feature_extractor.encoder.layer.7.attention.output.dense.bias True\n",
      "feature_extractor.encoder.layer.7.attention.output.LayerNorm.weight True\n",
      "feature_extractor.encoder.layer.7.attention.output.LayerNorm.bias True\n",
      "feature_extractor.encoder.layer.7.intermediate.dense.weight True\n",
      "feature_extractor.encoder.layer.7.intermediate.dense.bias True\n",
      "feature_extractor.encoder.layer.7.output.dense.weight True\n",
      "feature_extractor.encoder.layer.7.output.dense.bias True\n",
      "feature_extractor.encoder.layer.7.output.LayerNorm.weight True\n",
      "feature_extractor.encoder.layer.7.output.LayerNorm.bias True\n",
      "feature_extractor.encoder.layer.8.attention.self.query.weight True\n",
      "feature_extractor.encoder.layer.8.attention.self.query.bias True\n",
      "feature_extractor.encoder.layer.8.attention.self.key.weight True\n",
      "feature_extractor.encoder.layer.8.attention.self.key.bias True\n",
      "feature_extractor.encoder.layer.8.attention.self.value.weight True\n",
      "feature_extractor.encoder.layer.8.attention.self.value.bias True\n",
      "feature_extractor.encoder.layer.8.attention.output.dense.weight True\n",
      "feature_extractor.encoder.layer.8.attention.output.dense.bias True\n",
      "feature_extractor.encoder.layer.8.attention.output.LayerNorm.weight True\n",
      "feature_extractor.encoder.layer.8.attention.output.LayerNorm.bias True\n",
      "feature_extractor.encoder.layer.8.intermediate.dense.weight True\n",
      "feature_extractor.encoder.layer.8.intermediate.dense.bias True\n",
      "feature_extractor.encoder.layer.8.output.dense.weight True\n",
      "feature_extractor.encoder.layer.8.output.dense.bias True\n",
      "feature_extractor.encoder.layer.8.output.LayerNorm.weight True\n",
      "feature_extractor.encoder.layer.8.output.LayerNorm.bias True\n",
      "feature_extractor.encoder.layer.9.attention.self.query.weight True\n",
      "feature_extractor.encoder.layer.9.attention.self.query.bias True\n",
      "feature_extractor.encoder.layer.9.attention.self.key.weight True\n",
      "feature_extractor.encoder.layer.9.attention.self.key.bias True\n",
      "feature_extractor.encoder.layer.9.attention.self.value.weight True\n",
      "feature_extractor.encoder.layer.9.attention.self.value.bias True\n",
      "feature_extractor.encoder.layer.9.attention.output.dense.weight True\n",
      "feature_extractor.encoder.layer.9.attention.output.dense.bias True\n",
      "feature_extractor.encoder.layer.9.attention.output.LayerNorm.weight True\n",
      "feature_extractor.encoder.layer.9.attention.output.LayerNorm.bias True\n",
      "feature_extractor.encoder.layer.9.intermediate.dense.weight True\n",
      "feature_extractor.encoder.layer.9.intermediate.dense.bias True\n",
      "feature_extractor.encoder.layer.9.output.dense.weight True\n",
      "feature_extractor.encoder.layer.9.output.dense.bias True\n",
      "feature_extractor.encoder.layer.9.output.LayerNorm.weight True\n",
      "feature_extractor.encoder.layer.9.output.LayerNorm.bias True\n",
      "feature_extractor.encoder.layer.10.attention.self.query.weight True\n",
      "feature_extractor.encoder.layer.10.attention.self.query.bias True\n",
      "feature_extractor.encoder.layer.10.attention.self.key.weight True\n",
      "feature_extractor.encoder.layer.10.attention.self.key.bias True\n",
      "feature_extractor.encoder.layer.10.attention.self.value.weight True\n",
      "feature_extractor.encoder.layer.10.attention.self.value.bias True\n",
      "feature_extractor.encoder.layer.10.attention.output.dense.weight True\n",
      "feature_extractor.encoder.layer.10.attention.output.dense.bias True\n",
      "feature_extractor.encoder.layer.10.attention.output.LayerNorm.weight True\n",
      "feature_extractor.encoder.layer.10.attention.output.LayerNorm.bias True\n",
      "feature_extractor.encoder.layer.10.intermediate.dense.weight True\n",
      "feature_extractor.encoder.layer.10.intermediate.dense.bias True\n",
      "feature_extractor.encoder.layer.10.output.dense.weight True\n",
      "feature_extractor.encoder.layer.10.output.dense.bias True\n",
      "feature_extractor.encoder.layer.10.output.LayerNorm.weight True\n",
      "feature_extractor.encoder.layer.10.output.LayerNorm.bias True\n",
      "feature_extractor.encoder.layer.11.attention.self.query.weight True\n",
      "feature_extractor.encoder.layer.11.attention.self.query.bias True\n",
      "feature_extractor.encoder.layer.11.attention.self.key.weight True\n",
      "feature_extractor.encoder.layer.11.attention.self.key.bias True\n",
      "feature_extractor.encoder.layer.11.attention.self.value.weight True\n",
      "feature_extractor.encoder.layer.11.attention.self.value.bias True\n",
      "feature_extractor.encoder.layer.11.attention.output.dense.weight True\n",
      "feature_extractor.encoder.layer.11.attention.output.dense.bias True\n",
      "feature_extractor.encoder.layer.11.attention.output.LayerNorm.weight True\n",
      "feature_extractor.encoder.layer.11.attention.output.LayerNorm.bias True\n",
      "feature_extractor.encoder.layer.11.intermediate.dense.weight True\n",
      "feature_extractor.encoder.layer.11.intermediate.dense.bias True\n",
      "feature_extractor.encoder.layer.11.output.dense.weight True\n",
      "feature_extractor.encoder.layer.11.output.dense.bias True\n",
      "feature_extractor.encoder.layer.11.output.LayerNorm.weight True\n",
      "feature_extractor.encoder.layer.11.output.LayerNorm.bias True\n",
      "feature_extractor.pooler.dense.weight True\n",
      "feature_extractor.pooler.dense.bias True\n",
      "head.weight True\n",
      "head.bias True\n",
      "arc.W True\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "3it [00:00, 11.46it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train loss: 0.7202634215354919\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "23it [00:01, 12.64it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train loss: 0.7155327513104394\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "43it [00:03, 12.68it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train loss: 0.7149899820002114\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "63it [00:05, 12.68it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train loss: 0.7155885628012361\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "83it [00:06, 12.68it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train loss: 0.7163022808086725\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "103it [00:08, 12.69it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train loss: 0.7166965940211079\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "123it [00:09, 12.70it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train loss: 0.7168674996076536\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "143it [00:11, 12.69it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train loss: 0.7168829352297681\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "163it [00:12, 12.68it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train loss: 0.717056851949751\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "183it [00:14, 12.67it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train loss: 0.7170198128368315\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "203it [00:16, 12.68it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train loss: 0.7172196365114468\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "223it [00:17, 12.70it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train loss: 0.7170247896764074\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "225it [00:17, 12.65it/s]\n",
      "100%|█████████████████████████████████████████| 225/225 [00:09<00:00, 24.06it/s]\n",
      "100%|███████████████████████████████████████████| 61/61 [00:02<00:00, 22.45it/s]\n",
      "/mnt/disk2/ndubrovnyi/words_similarity/.venv/lib/python3.8/site-packages/sklearn/neighbors/_nearest_centroid.py:168: UserWarning: Averaging for metrics other than euclidean and manhattan not supported. The average is set to be the mean.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 22\n",
      "Train Loss: 0.7172691737280952\n",
      "ACC@3: 0.9136152656008252\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "3it [00:00, 10.57it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train loss: 0.7215237617492676\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "23it [00:01, 12.63it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train loss: 0.7110871360415504\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "43it [00:03, 12.69it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train loss: 0.7132676156555734\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "63it [00:05, 12.70it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train loss: 0.7145174106613534\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "83it [00:06, 12.68it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train loss: 0.7162438756153907\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "103it [00:08, 12.68it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train loss: 0.7167388737791835\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "123it [00:09, 12.66it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train loss: 0.7159951733163565\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "143it [00:11, 12.68it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train loss: 0.7160114891140174\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "163it [00:12, 12.67it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train loss: 0.7161891434503638\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "183it [00:14, 12.66it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train loss: 0.7164815255950169\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "203it [00:16, 12.68it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train loss: 0.7165523731886451\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "223it [00:17, 12.69it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train loss: 0.7165872934716859\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "225it [00:17, 12.64it/s]\n",
      "100%|█████████████████████████████████████████| 225/225 [00:09<00:00, 24.15it/s]\n",
      "100%|███████████████████████████████████████████| 61/61 [00:02<00:00, 22.55it/s]\n",
      "/mnt/disk2/ndubrovnyi/words_similarity/.venv/lib/python3.8/site-packages/sklearn/neighbors/_nearest_centroid.py:168: UserWarning: Averaging for metrics other than euclidean and manhattan not supported. The average is set to be the mean.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 23\n",
      "Train Loss: 0.716827569272783\n",
      "ACC@3: 0.9149045899948427\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "3it [00:00, 10.71it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train loss: 0.7429233193397522\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "23it [00:01, 12.63it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train loss: 0.7157170034590221\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "43it [00:03, 12.62it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train loss: 0.7143683535296742\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "63it [00:05, 12.61it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train loss: 0.7126413163591604\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "83it [00:06, 12.63it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train loss: 0.7124570460967076\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "103it [00:08, 12.64it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train loss: 0.7127875496845434\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "123it [00:09, 12.62it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train loss: 0.7132051848182993\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "143it [00:11, 12.65it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train loss: 0.7132957345204995\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "163it [00:12, 12.65it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train loss: 0.7132635353514867\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "183it [00:14, 12.63it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train loss: 0.7133030361233496\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "203it [00:16, 12.63it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train loss: 0.7141263840803459\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "223it [00:17, 12.65it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train loss: 0.7142662503061251\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "225it [00:17, 12.59it/s]\n",
      "100%|█████████████████████████████████████████| 225/225 [00:09<00:00, 24.01it/s]\n",
      "100%|███████████████████████████████████████████| 61/61 [00:02<00:00, 22.74it/s]\n",
      "/mnt/disk2/ndubrovnyi/words_similarity/.venv/lib/python3.8/site-packages/sklearn/neighbors/_nearest_centroid.py:168: UserWarning: Averaging for metrics other than euclidean and manhattan not supported. The average is set to be the mean.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 24\n",
      "Train Loss: 0.7141584142049153\n",
      "ACC@3: 0.9138731304796287\n",
      "feature_extractor.embeddings.word_embeddings.weight False\n",
      "feature_extractor.embeddings.position_embeddings.weight False\n",
      "feature_extractor.embeddings.token_type_embeddings.weight False\n",
      "feature_extractor.embeddings.LayerNorm.weight False\n",
      "feature_extractor.embeddings.LayerNorm.bias False\n",
      "feature_extractor.encoder.layer.0.attention.self.query.weight False\n",
      "feature_extractor.encoder.layer.0.attention.self.query.bias False\n",
      "feature_extractor.encoder.layer.0.attention.self.key.weight False\n",
      "feature_extractor.encoder.layer.0.attention.self.key.bias False\n",
      "feature_extractor.encoder.layer.0.attention.self.value.weight False\n",
      "feature_extractor.encoder.layer.0.attention.self.value.bias False\n",
      "feature_extractor.encoder.layer.0.attention.output.dense.weight False\n",
      "feature_extractor.encoder.layer.0.attention.output.dense.bias False\n",
      "feature_extractor.encoder.layer.0.attention.output.LayerNorm.weight False\n",
      "feature_extractor.encoder.layer.0.attention.output.LayerNorm.bias False\n",
      "feature_extractor.encoder.layer.0.intermediate.dense.weight False\n",
      "feature_extractor.encoder.layer.0.intermediate.dense.bias False\n",
      "feature_extractor.encoder.layer.0.output.dense.weight False\n",
      "feature_extractor.encoder.layer.0.output.dense.bias False\n",
      "feature_extractor.encoder.layer.0.output.LayerNorm.weight False\n",
      "feature_extractor.encoder.layer.0.output.LayerNorm.bias False\n",
      "feature_extractor.encoder.layer.1.attention.self.query.weight False\n",
      "feature_extractor.encoder.layer.1.attention.self.query.bias False\n",
      "feature_extractor.encoder.layer.1.attention.self.key.weight False\n",
      "feature_extractor.encoder.layer.1.attention.self.key.bias False\n",
      "feature_extractor.encoder.layer.1.attention.self.value.weight False\n",
      "feature_extractor.encoder.layer.1.attention.self.value.bias False\n",
      "feature_extractor.encoder.layer.1.attention.output.dense.weight False\n",
      "feature_extractor.encoder.layer.1.attention.output.dense.bias False\n",
      "feature_extractor.encoder.layer.1.attention.output.LayerNorm.weight False\n",
      "feature_extractor.encoder.layer.1.attention.output.LayerNorm.bias False\n",
      "feature_extractor.encoder.layer.1.intermediate.dense.weight False\n",
      "feature_extractor.encoder.layer.1.intermediate.dense.bias False\n",
      "feature_extractor.encoder.layer.1.output.dense.weight False\n",
      "feature_extractor.encoder.layer.1.output.dense.bias False\n",
      "feature_extractor.encoder.layer.1.output.LayerNorm.weight False\n",
      "feature_extractor.encoder.layer.1.output.LayerNorm.bias False\n",
      "feature_extractor.encoder.layer.2.attention.self.query.weight False\n",
      "feature_extractor.encoder.layer.2.attention.self.query.bias False\n",
      "feature_extractor.encoder.layer.2.attention.self.key.weight False\n",
      "feature_extractor.encoder.layer.2.attention.self.key.bias False\n",
      "feature_extractor.encoder.layer.2.attention.self.value.weight False\n",
      "feature_extractor.encoder.layer.2.attention.self.value.bias False\n",
      "feature_extractor.encoder.layer.2.attention.output.dense.weight False\n",
      "feature_extractor.encoder.layer.2.attention.output.dense.bias False\n",
      "feature_extractor.encoder.layer.2.attention.output.LayerNorm.weight False\n",
      "feature_extractor.encoder.layer.2.attention.output.LayerNorm.bias False\n",
      "feature_extractor.encoder.layer.2.intermediate.dense.weight False\n",
      "feature_extractor.encoder.layer.2.intermediate.dense.bias False\n",
      "feature_extractor.encoder.layer.2.output.dense.weight False\n",
      "feature_extractor.encoder.layer.2.output.dense.bias False\n",
      "feature_extractor.encoder.layer.2.output.LayerNorm.weight False\n",
      "feature_extractor.encoder.layer.2.output.LayerNorm.bias False\n",
      "feature_extractor.encoder.layer.3.attention.self.query.weight False\n",
      "feature_extractor.encoder.layer.3.attention.self.query.bias False\n",
      "feature_extractor.encoder.layer.3.attention.self.key.weight False\n",
      "feature_extractor.encoder.layer.3.attention.self.key.bias False\n",
      "feature_extractor.encoder.layer.3.attention.self.value.weight False\n",
      "feature_extractor.encoder.layer.3.attention.self.value.bias False\n",
      "feature_extractor.encoder.layer.3.attention.output.dense.weight False\n",
      "feature_extractor.encoder.layer.3.attention.output.dense.bias False\n",
      "feature_extractor.encoder.layer.3.attention.output.LayerNorm.weight False\n",
      "feature_extractor.encoder.layer.3.attention.output.LayerNorm.bias False\n",
      "feature_extractor.encoder.layer.3.intermediate.dense.weight False\n",
      "feature_extractor.encoder.layer.3.intermediate.dense.bias False\n",
      "feature_extractor.encoder.layer.3.output.dense.weight False\n",
      "feature_extractor.encoder.layer.3.output.dense.bias False\n",
      "feature_extractor.encoder.layer.3.output.LayerNorm.weight False\n",
      "feature_extractor.encoder.layer.3.output.LayerNorm.bias False\n",
      "feature_extractor.encoder.layer.4.attention.self.query.weight False\n",
      "feature_extractor.encoder.layer.4.attention.self.query.bias False\n",
      "feature_extractor.encoder.layer.4.attention.self.key.weight False\n",
      "feature_extractor.encoder.layer.4.attention.self.key.bias False\n",
      "feature_extractor.encoder.layer.4.attention.self.value.weight False\n",
      "feature_extractor.encoder.layer.4.attention.self.value.bias False\n",
      "feature_extractor.encoder.layer.4.attention.output.dense.weight False\n",
      "feature_extractor.encoder.layer.4.attention.output.dense.bias False\n",
      "feature_extractor.encoder.layer.4.attention.output.LayerNorm.weight False\n",
      "feature_extractor.encoder.layer.4.attention.output.LayerNorm.bias False\n",
      "feature_extractor.encoder.layer.4.intermediate.dense.weight False\n",
      "feature_extractor.encoder.layer.4.intermediate.dense.bias False\n",
      "feature_extractor.encoder.layer.4.output.dense.weight False\n",
      "feature_extractor.encoder.layer.4.output.dense.bias False\n",
      "feature_extractor.encoder.layer.4.output.LayerNorm.weight False\n",
      "feature_extractor.encoder.layer.4.output.LayerNorm.bias False\n",
      "feature_extractor.encoder.layer.5.attention.self.query.weight False\n",
      "feature_extractor.encoder.layer.5.attention.self.query.bias False\n",
      "feature_extractor.encoder.layer.5.attention.self.key.weight False\n",
      "feature_extractor.encoder.layer.5.attention.self.key.bias False\n",
      "feature_extractor.encoder.layer.5.attention.self.value.weight False\n",
      "feature_extractor.encoder.layer.5.attention.self.value.bias False\n",
      "feature_extractor.encoder.layer.5.attention.output.dense.weight False\n",
      "feature_extractor.encoder.layer.5.attention.output.dense.bias False\n",
      "feature_extractor.encoder.layer.5.attention.output.LayerNorm.weight False\n",
      "feature_extractor.encoder.layer.5.attention.output.LayerNorm.bias False\n",
      "feature_extractor.encoder.layer.5.intermediate.dense.weight False\n",
      "feature_extractor.encoder.layer.5.intermediate.dense.bias False\n",
      "feature_extractor.encoder.layer.5.output.dense.weight False\n",
      "feature_extractor.encoder.layer.5.output.dense.bias False\n",
      "feature_extractor.encoder.layer.5.output.LayerNorm.weight False\n",
      "feature_extractor.encoder.layer.5.output.LayerNorm.bias False\n",
      "feature_extractor.encoder.layer.6.attention.self.query.weight True\n",
      "feature_extractor.encoder.layer.6.attention.self.query.bias True\n",
      "feature_extractor.encoder.layer.6.attention.self.key.weight True\n",
      "feature_extractor.encoder.layer.6.attention.self.key.bias True\n",
      "feature_extractor.encoder.layer.6.attention.self.value.weight True\n",
      "feature_extractor.encoder.layer.6.attention.self.value.bias True\n",
      "feature_extractor.encoder.layer.6.attention.output.dense.weight True\n",
      "feature_extractor.encoder.layer.6.attention.output.dense.bias True\n",
      "feature_extractor.encoder.layer.6.attention.output.LayerNorm.weight True\n",
      "feature_extractor.encoder.layer.6.attention.output.LayerNorm.bias True\n",
      "feature_extractor.encoder.layer.6.intermediate.dense.weight True\n",
      "feature_extractor.encoder.layer.6.intermediate.dense.bias True\n",
      "feature_extractor.encoder.layer.6.output.dense.weight True\n",
      "feature_extractor.encoder.layer.6.output.dense.bias True\n",
      "feature_extractor.encoder.layer.6.output.LayerNorm.weight True\n",
      "feature_extractor.encoder.layer.6.output.LayerNorm.bias True\n",
      "feature_extractor.encoder.layer.7.attention.self.query.weight True\n",
      "feature_extractor.encoder.layer.7.attention.self.query.bias True\n",
      "feature_extractor.encoder.layer.7.attention.self.key.weight True\n",
      "feature_extractor.encoder.layer.7.attention.self.key.bias True\n",
      "feature_extractor.encoder.layer.7.attention.self.value.weight True\n",
      "feature_extractor.encoder.layer.7.attention.self.value.bias True\n",
      "feature_extractor.encoder.layer.7.attention.output.dense.weight True\n",
      "feature_extractor.encoder.layer.7.attention.output.dense.bias True\n",
      "feature_extractor.encoder.layer.7.attention.output.LayerNorm.weight True\n",
      "feature_extractor.encoder.layer.7.attention.output.LayerNorm.bias True\n",
      "feature_extractor.encoder.layer.7.intermediate.dense.weight True\n",
      "feature_extractor.encoder.layer.7.intermediate.dense.bias True\n",
      "feature_extractor.encoder.layer.7.output.dense.weight True\n",
      "feature_extractor.encoder.layer.7.output.dense.bias True\n",
      "feature_extractor.encoder.layer.7.output.LayerNorm.weight True\n",
      "feature_extractor.encoder.layer.7.output.LayerNorm.bias True\n",
      "feature_extractor.encoder.layer.8.attention.self.query.weight True\n",
      "feature_extractor.encoder.layer.8.attention.self.query.bias True\n",
      "feature_extractor.encoder.layer.8.attention.self.key.weight True\n",
      "feature_extractor.encoder.layer.8.attention.self.key.bias True\n",
      "feature_extractor.encoder.layer.8.attention.self.value.weight True\n",
      "feature_extractor.encoder.layer.8.attention.self.value.bias True\n",
      "feature_extractor.encoder.layer.8.attention.output.dense.weight True\n",
      "feature_extractor.encoder.layer.8.attention.output.dense.bias True\n",
      "feature_extractor.encoder.layer.8.attention.output.LayerNorm.weight True\n",
      "feature_extractor.encoder.layer.8.attention.output.LayerNorm.bias True\n",
      "feature_extractor.encoder.layer.8.intermediate.dense.weight True\n",
      "feature_extractor.encoder.layer.8.intermediate.dense.bias True\n",
      "feature_extractor.encoder.layer.8.output.dense.weight True\n",
      "feature_extractor.encoder.layer.8.output.dense.bias True\n",
      "feature_extractor.encoder.layer.8.output.LayerNorm.weight True\n",
      "feature_extractor.encoder.layer.8.output.LayerNorm.bias True\n",
      "feature_extractor.encoder.layer.9.attention.self.query.weight True\n",
      "feature_extractor.encoder.layer.9.attention.self.query.bias True\n",
      "feature_extractor.encoder.layer.9.attention.self.key.weight True\n",
      "feature_extractor.encoder.layer.9.attention.self.key.bias True\n",
      "feature_extractor.encoder.layer.9.attention.self.value.weight True\n",
      "feature_extractor.encoder.layer.9.attention.self.value.bias True\n",
      "feature_extractor.encoder.layer.9.attention.output.dense.weight True\n",
      "feature_extractor.encoder.layer.9.attention.output.dense.bias True\n",
      "feature_extractor.encoder.layer.9.attention.output.LayerNorm.weight True\n",
      "feature_extractor.encoder.layer.9.attention.output.LayerNorm.bias True\n",
      "feature_extractor.encoder.layer.9.intermediate.dense.weight True\n",
      "feature_extractor.encoder.layer.9.intermediate.dense.bias True\n",
      "feature_extractor.encoder.layer.9.output.dense.weight True\n",
      "feature_extractor.encoder.layer.9.output.dense.bias True\n",
      "feature_extractor.encoder.layer.9.output.LayerNorm.weight True\n",
      "feature_extractor.encoder.layer.9.output.LayerNorm.bias True\n",
      "feature_extractor.encoder.layer.10.attention.self.query.weight True\n",
      "feature_extractor.encoder.layer.10.attention.self.query.bias True\n",
      "feature_extractor.encoder.layer.10.attention.self.key.weight True\n",
      "feature_extractor.encoder.layer.10.attention.self.key.bias True\n",
      "feature_extractor.encoder.layer.10.attention.self.value.weight True\n",
      "feature_extractor.encoder.layer.10.attention.self.value.bias True\n",
      "feature_extractor.encoder.layer.10.attention.output.dense.weight True\n",
      "feature_extractor.encoder.layer.10.attention.output.dense.bias True\n",
      "feature_extractor.encoder.layer.10.attention.output.LayerNorm.weight True\n",
      "feature_extractor.encoder.layer.10.attention.output.LayerNorm.bias True\n",
      "feature_extractor.encoder.layer.10.intermediate.dense.weight True\n",
      "feature_extractor.encoder.layer.10.intermediate.dense.bias True\n",
      "feature_extractor.encoder.layer.10.output.dense.weight True\n",
      "feature_extractor.encoder.layer.10.output.dense.bias True\n",
      "feature_extractor.encoder.layer.10.output.LayerNorm.weight True\n",
      "feature_extractor.encoder.layer.10.output.LayerNorm.bias True\n",
      "feature_extractor.encoder.layer.11.attention.self.query.weight True\n",
      "feature_extractor.encoder.layer.11.attention.self.query.bias True\n",
      "feature_extractor.encoder.layer.11.attention.self.key.weight True\n",
      "feature_extractor.encoder.layer.11.attention.self.key.bias True\n",
      "feature_extractor.encoder.layer.11.attention.self.value.weight True\n",
      "feature_extractor.encoder.layer.11.attention.self.value.bias True\n",
      "feature_extractor.encoder.layer.11.attention.output.dense.weight True\n",
      "feature_extractor.encoder.layer.11.attention.output.dense.bias True\n",
      "feature_extractor.encoder.layer.11.attention.output.LayerNorm.weight True\n",
      "feature_extractor.encoder.layer.11.attention.output.LayerNorm.bias True\n",
      "feature_extractor.encoder.layer.11.intermediate.dense.weight True\n",
      "feature_extractor.encoder.layer.11.intermediate.dense.bias True\n",
      "feature_extractor.encoder.layer.11.output.dense.weight True\n",
      "feature_extractor.encoder.layer.11.output.dense.bias True\n",
      "feature_extractor.encoder.layer.11.output.LayerNorm.weight True\n",
      "feature_extractor.encoder.layer.11.output.LayerNorm.bias True\n",
      "feature_extractor.pooler.dense.weight True\n",
      "feature_extractor.pooler.dense.bias True\n",
      "head.weight True\n",
      "head.bias True\n",
      "arc.W True\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "3it [00:00, 10.56it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train loss: 0.7192206978797913\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "23it [00:02, 11.64it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train loss: 0.713834319795881\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "43it [00:03, 11.63it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train loss: 0.7139142170184996\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "63it [00:05, 11.66it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train loss: 0.7130963821880153\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "83it [00:07, 11.65it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train loss: 0.713878721366694\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "103it [00:08, 11.64it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train loss: 0.713766609678174\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "123it [00:10, 11.63it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train loss: 0.7141606994896881\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "143it [00:12, 11.62it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train loss: 0.7143261563693378\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "163it [00:14, 11.64it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train loss: 0.7138915206334606\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "183it [00:15, 11.64it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train loss: 0.7138826741698039\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "203it [00:17, 11.58it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train loss: 0.7138096696108728\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "223it [00:19, 11.65it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train loss: 0.7138162657146541\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "225it [00:19, 11.62it/s]\n",
      "100%|█████████████████████████████████████████| 225/225 [00:09<00:00, 24.07it/s]\n",
      "100%|███████████████████████████████████████████| 61/61 [00:02<00:00, 22.69it/s]\n",
      "/mnt/disk2/ndubrovnyi/words_similarity/.venv/lib/python3.8/site-packages/sklearn/neighbors/_nearest_centroid.py:168: UserWarning: Averaging for metrics other than euclidean and manhattan not supported. The average is set to be the mean.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 25\n",
      "Train Loss: 0.7138596725463867\n",
      "ACC@3: 0.9138731304796287\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "3it [00:00, 10.69it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train loss: 0.7085270881652832\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "23it [00:02, 11.64it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train loss: 0.7123456966309321\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "43it [00:03, 11.66it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train loss: 0.7117762987206622\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "63it [00:05, 11.65it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train loss: 0.7122880875087175\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "83it [00:07, 11.64it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train loss: 0.7122086536737136\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "103it [00:08, 11.64it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train loss: 0.7120579138840779\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "123it [00:10, 11.64it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train loss: 0.711961241300441\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "143it [00:12, 11.65it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train loss: 0.7119684295451387\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "163it [00:14, 11.65it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train loss: 0.7118098606234011\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "183it [00:15, 11.64it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train loss: 0.7121664282366715\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "203it [00:17, 11.65it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train loss: 0.7122979801685656\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "223it [00:19, 11.65it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train loss: 0.7123133472727434\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "225it [00:19, 11.63it/s]\n",
      "100%|█████████████████████████████████████████| 225/225 [00:09<00:00, 24.09it/s]\n",
      "100%|███████████████████████████████████████████| 61/61 [00:02<00:00, 22.64it/s]\n",
      "/mnt/disk2/ndubrovnyi/words_similarity/.venv/lib/python3.8/site-packages/sklearn/neighbors/_nearest_centroid.py:168: UserWarning: Averaging for metrics other than euclidean and manhattan not supported. The average is set to be the mean.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 26\n",
      "Train Loss: 0.7123902519543965\n",
      "ACC@3: 0.9136152656008252\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "3it [00:00, 10.46it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train loss: 0.6933297514915466\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "23it [00:02, 11.64it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train loss: 0.7117457474981036\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "43it [00:03, 11.63it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train loss: 0.7124948734190406\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "63it [00:05, 11.63it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train loss: 0.7120424157283345\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "83it [00:07, 11.63it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train loss: 0.7122144949289015\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "103it [00:08, 11.64it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train loss: 0.7121522060715326\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "123it [00:10, 11.64it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train loss: 0.7122956775436716\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "143it [00:12, 11.64it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train loss: 0.7125593335070508\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "163it [00:14, 11.63it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train loss: 0.7125981039142016\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "183it [00:15, 11.63it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train loss: 0.7124057040030126\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "203it [00:17, 11.65it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train loss: 0.7122866520241126\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "223it [00:19, 11.64it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train loss: 0.7122801046026238\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "225it [00:19, 11.61it/s]\n",
      "100%|█████████████████████████████████████████| 225/225 [00:09<00:00, 24.02it/s]\n",
      "100%|███████████████████████████████████████████| 61/61 [00:02<00:00, 22.69it/s]\n",
      "/mnt/disk2/ndubrovnyi/words_similarity/.venv/lib/python3.8/site-packages/sklearn/neighbors/_nearest_centroid.py:168: UserWarning: Averaging for metrics other than euclidean and manhattan not supported. The average is set to be the mean.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 27\n",
      "Train Loss: 0.7124055785602993\n",
      "ACC@3: 0.9138731304796287\n",
      "feature_extractor.embeddings.word_embeddings.weight False\n",
      "feature_extractor.embeddings.position_embeddings.weight False\n",
      "feature_extractor.embeddings.token_type_embeddings.weight False\n",
      "feature_extractor.embeddings.LayerNorm.weight False\n",
      "feature_extractor.embeddings.LayerNorm.bias False\n",
      "feature_extractor.encoder.layer.0.attention.self.query.weight False\n",
      "feature_extractor.encoder.layer.0.attention.self.query.bias False\n",
      "feature_extractor.encoder.layer.0.attention.self.key.weight False\n",
      "feature_extractor.encoder.layer.0.attention.self.key.bias False\n",
      "feature_extractor.encoder.layer.0.attention.self.value.weight False\n",
      "feature_extractor.encoder.layer.0.attention.self.value.bias False\n",
      "feature_extractor.encoder.layer.0.attention.output.dense.weight False\n",
      "feature_extractor.encoder.layer.0.attention.output.dense.bias False\n",
      "feature_extractor.encoder.layer.0.attention.output.LayerNorm.weight False\n",
      "feature_extractor.encoder.layer.0.attention.output.LayerNorm.bias False\n",
      "feature_extractor.encoder.layer.0.intermediate.dense.weight False\n",
      "feature_extractor.encoder.layer.0.intermediate.dense.bias False\n",
      "feature_extractor.encoder.layer.0.output.dense.weight False\n",
      "feature_extractor.encoder.layer.0.output.dense.bias False\n",
      "feature_extractor.encoder.layer.0.output.LayerNorm.weight False\n",
      "feature_extractor.encoder.layer.0.output.LayerNorm.bias False\n",
      "feature_extractor.encoder.layer.1.attention.self.query.weight False\n",
      "feature_extractor.encoder.layer.1.attention.self.query.bias False\n",
      "feature_extractor.encoder.layer.1.attention.self.key.weight False\n",
      "feature_extractor.encoder.layer.1.attention.self.key.bias False\n",
      "feature_extractor.encoder.layer.1.attention.self.value.weight False\n",
      "feature_extractor.encoder.layer.1.attention.self.value.bias False\n",
      "feature_extractor.encoder.layer.1.attention.output.dense.weight False\n",
      "feature_extractor.encoder.layer.1.attention.output.dense.bias False\n",
      "feature_extractor.encoder.layer.1.attention.output.LayerNorm.weight False\n",
      "feature_extractor.encoder.layer.1.attention.output.LayerNorm.bias False\n",
      "feature_extractor.encoder.layer.1.intermediate.dense.weight False\n",
      "feature_extractor.encoder.layer.1.intermediate.dense.bias False\n",
      "feature_extractor.encoder.layer.1.output.dense.weight False\n",
      "feature_extractor.encoder.layer.1.output.dense.bias False\n",
      "feature_extractor.encoder.layer.1.output.LayerNorm.weight False\n",
      "feature_extractor.encoder.layer.1.output.LayerNorm.bias False\n",
      "feature_extractor.encoder.layer.2.attention.self.query.weight False\n",
      "feature_extractor.encoder.layer.2.attention.self.query.bias False\n",
      "feature_extractor.encoder.layer.2.attention.self.key.weight False\n",
      "feature_extractor.encoder.layer.2.attention.self.key.bias False\n",
      "feature_extractor.encoder.layer.2.attention.self.value.weight False\n",
      "feature_extractor.encoder.layer.2.attention.self.value.bias False\n",
      "feature_extractor.encoder.layer.2.attention.output.dense.weight False\n",
      "feature_extractor.encoder.layer.2.attention.output.dense.bias False\n",
      "feature_extractor.encoder.layer.2.attention.output.LayerNorm.weight False\n",
      "feature_extractor.encoder.layer.2.attention.output.LayerNorm.bias False\n",
      "feature_extractor.encoder.layer.2.intermediate.dense.weight False\n",
      "feature_extractor.encoder.layer.2.intermediate.dense.bias False\n",
      "feature_extractor.encoder.layer.2.output.dense.weight False\n",
      "feature_extractor.encoder.layer.2.output.dense.bias False\n",
      "feature_extractor.encoder.layer.2.output.LayerNorm.weight False\n",
      "feature_extractor.encoder.layer.2.output.LayerNorm.bias False\n",
      "feature_extractor.encoder.layer.3.attention.self.query.weight False\n",
      "feature_extractor.encoder.layer.3.attention.self.query.bias False\n",
      "feature_extractor.encoder.layer.3.attention.self.key.weight False\n",
      "feature_extractor.encoder.layer.3.attention.self.key.bias False\n",
      "feature_extractor.encoder.layer.3.attention.self.value.weight False\n",
      "feature_extractor.encoder.layer.3.attention.self.value.bias False\n",
      "feature_extractor.encoder.layer.3.attention.output.dense.weight False\n",
      "feature_extractor.encoder.layer.3.attention.output.dense.bias False\n",
      "feature_extractor.encoder.layer.3.attention.output.LayerNorm.weight False\n",
      "feature_extractor.encoder.layer.3.attention.output.LayerNorm.bias False\n",
      "feature_extractor.encoder.layer.3.intermediate.dense.weight False\n",
      "feature_extractor.encoder.layer.3.intermediate.dense.bias False\n",
      "feature_extractor.encoder.layer.3.output.dense.weight False\n",
      "feature_extractor.encoder.layer.3.output.dense.bias False\n",
      "feature_extractor.encoder.layer.3.output.LayerNorm.weight False\n",
      "feature_extractor.encoder.layer.3.output.LayerNorm.bias False\n",
      "feature_extractor.encoder.layer.4.attention.self.query.weight False\n",
      "feature_extractor.encoder.layer.4.attention.self.query.bias False\n",
      "feature_extractor.encoder.layer.4.attention.self.key.weight False\n",
      "feature_extractor.encoder.layer.4.attention.self.key.bias False\n",
      "feature_extractor.encoder.layer.4.attention.self.value.weight False\n",
      "feature_extractor.encoder.layer.4.attention.self.value.bias False\n",
      "feature_extractor.encoder.layer.4.attention.output.dense.weight False\n",
      "feature_extractor.encoder.layer.4.attention.output.dense.bias False\n",
      "feature_extractor.encoder.layer.4.attention.output.LayerNorm.weight False\n",
      "feature_extractor.encoder.layer.4.attention.output.LayerNorm.bias False\n",
      "feature_extractor.encoder.layer.4.intermediate.dense.weight False\n",
      "feature_extractor.encoder.layer.4.intermediate.dense.bias False\n",
      "feature_extractor.encoder.layer.4.output.dense.weight False\n",
      "feature_extractor.encoder.layer.4.output.dense.bias False\n",
      "feature_extractor.encoder.layer.4.output.LayerNorm.weight False\n",
      "feature_extractor.encoder.layer.4.output.LayerNorm.bias False\n",
      "feature_extractor.encoder.layer.5.attention.self.query.weight True\n",
      "feature_extractor.encoder.layer.5.attention.self.query.bias True\n",
      "feature_extractor.encoder.layer.5.attention.self.key.weight True\n",
      "feature_extractor.encoder.layer.5.attention.self.key.bias True\n",
      "feature_extractor.encoder.layer.5.attention.self.value.weight True\n",
      "feature_extractor.encoder.layer.5.attention.self.value.bias True\n",
      "feature_extractor.encoder.layer.5.attention.output.dense.weight True\n",
      "feature_extractor.encoder.layer.5.attention.output.dense.bias True\n",
      "feature_extractor.encoder.layer.5.attention.output.LayerNorm.weight True\n",
      "feature_extractor.encoder.layer.5.attention.output.LayerNorm.bias True\n",
      "feature_extractor.encoder.layer.5.intermediate.dense.weight True\n",
      "feature_extractor.encoder.layer.5.intermediate.dense.bias True\n",
      "feature_extractor.encoder.layer.5.output.dense.weight True\n",
      "feature_extractor.encoder.layer.5.output.dense.bias True\n",
      "feature_extractor.encoder.layer.5.output.LayerNorm.weight True\n",
      "feature_extractor.encoder.layer.5.output.LayerNorm.bias True\n",
      "feature_extractor.encoder.layer.6.attention.self.query.weight True\n",
      "feature_extractor.encoder.layer.6.attention.self.query.bias True\n",
      "feature_extractor.encoder.layer.6.attention.self.key.weight True\n",
      "feature_extractor.encoder.layer.6.attention.self.key.bias True\n",
      "feature_extractor.encoder.layer.6.attention.self.value.weight True\n",
      "feature_extractor.encoder.layer.6.attention.self.value.bias True\n",
      "feature_extractor.encoder.layer.6.attention.output.dense.weight True\n",
      "feature_extractor.encoder.layer.6.attention.output.dense.bias True\n",
      "feature_extractor.encoder.layer.6.attention.output.LayerNorm.weight True\n",
      "feature_extractor.encoder.layer.6.attention.output.LayerNorm.bias True\n",
      "feature_extractor.encoder.layer.6.intermediate.dense.weight True\n",
      "feature_extractor.encoder.layer.6.intermediate.dense.bias True\n",
      "feature_extractor.encoder.layer.6.output.dense.weight True\n",
      "feature_extractor.encoder.layer.6.output.dense.bias True\n",
      "feature_extractor.encoder.layer.6.output.LayerNorm.weight True\n",
      "feature_extractor.encoder.layer.6.output.LayerNorm.bias True\n",
      "feature_extractor.encoder.layer.7.attention.self.query.weight True\n",
      "feature_extractor.encoder.layer.7.attention.self.query.bias True\n",
      "feature_extractor.encoder.layer.7.attention.self.key.weight True\n",
      "feature_extractor.encoder.layer.7.attention.self.key.bias True\n",
      "feature_extractor.encoder.layer.7.attention.self.value.weight True\n",
      "feature_extractor.encoder.layer.7.attention.self.value.bias True\n",
      "feature_extractor.encoder.layer.7.attention.output.dense.weight True\n",
      "feature_extractor.encoder.layer.7.attention.output.dense.bias True\n",
      "feature_extractor.encoder.layer.7.attention.output.LayerNorm.weight True\n",
      "feature_extractor.encoder.layer.7.attention.output.LayerNorm.bias True\n",
      "feature_extractor.encoder.layer.7.intermediate.dense.weight True\n",
      "feature_extractor.encoder.layer.7.intermediate.dense.bias True\n",
      "feature_extractor.encoder.layer.7.output.dense.weight True\n",
      "feature_extractor.encoder.layer.7.output.dense.bias True\n",
      "feature_extractor.encoder.layer.7.output.LayerNorm.weight True\n",
      "feature_extractor.encoder.layer.7.output.LayerNorm.bias True\n",
      "feature_extractor.encoder.layer.8.attention.self.query.weight True\n",
      "feature_extractor.encoder.layer.8.attention.self.query.bias True\n",
      "feature_extractor.encoder.layer.8.attention.self.key.weight True\n",
      "feature_extractor.encoder.layer.8.attention.self.key.bias True\n",
      "feature_extractor.encoder.layer.8.attention.self.value.weight True\n",
      "feature_extractor.encoder.layer.8.attention.self.value.bias True\n",
      "feature_extractor.encoder.layer.8.attention.output.dense.weight True\n",
      "feature_extractor.encoder.layer.8.attention.output.dense.bias True\n",
      "feature_extractor.encoder.layer.8.attention.output.LayerNorm.weight True\n",
      "feature_extractor.encoder.layer.8.attention.output.LayerNorm.bias True\n",
      "feature_extractor.encoder.layer.8.intermediate.dense.weight True\n",
      "feature_extractor.encoder.layer.8.intermediate.dense.bias True\n",
      "feature_extractor.encoder.layer.8.output.dense.weight True\n",
      "feature_extractor.encoder.layer.8.output.dense.bias True\n",
      "feature_extractor.encoder.layer.8.output.LayerNorm.weight True\n",
      "feature_extractor.encoder.layer.8.output.LayerNorm.bias True\n",
      "feature_extractor.encoder.layer.9.attention.self.query.weight True\n",
      "feature_extractor.encoder.layer.9.attention.self.query.bias True\n",
      "feature_extractor.encoder.layer.9.attention.self.key.weight True\n",
      "feature_extractor.encoder.layer.9.attention.self.key.bias True\n",
      "feature_extractor.encoder.layer.9.attention.self.value.weight True\n",
      "feature_extractor.encoder.layer.9.attention.self.value.bias True\n",
      "feature_extractor.encoder.layer.9.attention.output.dense.weight True\n",
      "feature_extractor.encoder.layer.9.attention.output.dense.bias True\n",
      "feature_extractor.encoder.layer.9.attention.output.LayerNorm.weight True\n",
      "feature_extractor.encoder.layer.9.attention.output.LayerNorm.bias True\n",
      "feature_extractor.encoder.layer.9.intermediate.dense.weight True\n",
      "feature_extractor.encoder.layer.9.intermediate.dense.bias True\n",
      "feature_extractor.encoder.layer.9.output.dense.weight True\n",
      "feature_extractor.encoder.layer.9.output.dense.bias True\n",
      "feature_extractor.encoder.layer.9.output.LayerNorm.weight True\n",
      "feature_extractor.encoder.layer.9.output.LayerNorm.bias True\n",
      "feature_extractor.encoder.layer.10.attention.self.query.weight True\n",
      "feature_extractor.encoder.layer.10.attention.self.query.bias True\n",
      "feature_extractor.encoder.layer.10.attention.self.key.weight True\n",
      "feature_extractor.encoder.layer.10.attention.self.key.bias True\n",
      "feature_extractor.encoder.layer.10.attention.self.value.weight True\n",
      "feature_extractor.encoder.layer.10.attention.self.value.bias True\n",
      "feature_extractor.encoder.layer.10.attention.output.dense.weight True\n",
      "feature_extractor.encoder.layer.10.attention.output.dense.bias True\n",
      "feature_extractor.encoder.layer.10.attention.output.LayerNorm.weight True\n",
      "feature_extractor.encoder.layer.10.attention.output.LayerNorm.bias True\n",
      "feature_extractor.encoder.layer.10.intermediate.dense.weight True\n",
      "feature_extractor.encoder.layer.10.intermediate.dense.bias True\n",
      "feature_extractor.encoder.layer.10.output.dense.weight True\n",
      "feature_extractor.encoder.layer.10.output.dense.bias True\n",
      "feature_extractor.encoder.layer.10.output.LayerNorm.weight True\n",
      "feature_extractor.encoder.layer.10.output.LayerNorm.bias True\n",
      "feature_extractor.encoder.layer.11.attention.self.query.weight True\n",
      "feature_extractor.encoder.layer.11.attention.self.query.bias True\n",
      "feature_extractor.encoder.layer.11.attention.self.key.weight True\n",
      "feature_extractor.encoder.layer.11.attention.self.key.bias True\n",
      "feature_extractor.encoder.layer.11.attention.self.value.weight True\n",
      "feature_extractor.encoder.layer.11.attention.self.value.bias True\n",
      "feature_extractor.encoder.layer.11.attention.output.dense.weight True\n",
      "feature_extractor.encoder.layer.11.attention.output.dense.bias True\n",
      "feature_extractor.encoder.layer.11.attention.output.LayerNorm.weight True\n",
      "feature_extractor.encoder.layer.11.attention.output.LayerNorm.bias True\n",
      "feature_extractor.encoder.layer.11.intermediate.dense.weight True\n",
      "feature_extractor.encoder.layer.11.intermediate.dense.bias True\n",
      "feature_extractor.encoder.layer.11.output.dense.weight True\n",
      "feature_extractor.encoder.layer.11.output.dense.bias True\n",
      "feature_extractor.encoder.layer.11.output.LayerNorm.weight True\n",
      "feature_extractor.encoder.layer.11.output.LayerNorm.bias True\n",
      "feature_extractor.pooler.dense.weight True\n",
      "feature_extractor.pooler.dense.bias True\n",
      "head.weight True\n",
      "head.bias True\n",
      "arc.W True\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "3it [00:00,  9.95it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train loss: 0.7058812975883484\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "23it [00:02, 10.78it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train loss: 0.7088951610383534\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "43it [00:04, 10.78it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train loss: 0.7091580135066334\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "63it [00:05, 10.79it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train loss: 0.7095891637880294\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "83it [00:07, 10.78it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train loss: 0.7095220434812852\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "103it [00:09, 10.79it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train loss: 0.7108707304048066\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "123it [00:11, 10.79it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train loss: 0.7110644155297398\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "143it [00:13, 10.78it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train loss: 0.7110860533748112\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "163it [00:15, 10.79it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train loss: 0.7114049692331634\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "183it [00:16, 10.78it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train loss: 0.7112234159069166\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "203it [00:18, 10.79it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train loss: 0.7112644854469679\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "223it [00:20, 10.79it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train loss: 0.7111100821473479\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "225it [00:20, 10.77it/s]\n",
      "100%|█████████████████████████████████████████| 225/225 [00:09<00:00, 23.96it/s]\n",
      "100%|███████████████████████████████████████████| 61/61 [00:02<00:00, 22.46it/s]\n",
      "/mnt/disk2/ndubrovnyi/words_similarity/.venv/lib/python3.8/site-packages/sklearn/neighbors/_nearest_centroid.py:168: UserWarning: Averaging for metrics other than euclidean and manhattan not supported. The average is set to be the mean.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 28\n",
      "Train Loss: 0.7112635384665595\n",
      "ACC@3: 0.9138731304796287\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "3it [00:00,  9.61it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train loss: 0.708071768283844\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "23it [00:02, 10.77it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train loss: 0.711320820308867\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "43it [00:04, 10.78it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train loss: 0.711183901240186\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "63it [00:05, 10.78it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train loss: 0.7104288388471134\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "83it [00:07, 10.80it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train loss: 0.7102268132162682\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "103it [00:09, 10.78it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train loss: 0.7101969270422908\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "123it [00:11, 10.77it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train loss: 0.7102622340533359\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "143it [00:13, 10.80it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train loss: 0.710491789148209\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "163it [00:15, 10.79it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train loss: 0.7105903588466763\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "183it [00:16, 10.79it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train loss: 0.7105660132281688\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "203it [00:18, 10.78it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train loss: 0.7104976951186337\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "223it [00:20, 10.80it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train loss: 0.7105028602332552\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "225it [00:20, 10.77it/s]\n",
      "100%|█████████████████████████████████████████| 225/225 [00:09<00:00, 23.96it/s]\n",
      "100%|███████████████████████████████████████████| 61/61 [00:02<00:00, 22.46it/s]\n",
      "/mnt/disk2/ndubrovnyi/words_similarity/.venv/lib/python3.8/site-packages/sklearn/neighbors/_nearest_centroid.py:168: UserWarning: Averaging for metrics other than euclidean and manhattan not supported. The average is set to be the mean.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 29\n",
      "Train Loss: 0.7104825666215685\n",
      "ACC@3: 0.9136152656008252\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "3it [00:00,  9.90it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train loss: 0.7044153809547424\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "23it [00:02, 10.76it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train loss: 0.7099741385096595\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "43it [00:04, 10.78it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train loss: 0.7088037220443167\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "63it [00:05, 10.77it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train loss: 0.7079320637906183\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "83it [00:07, 10.76it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train loss: 0.7079795415018811\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "103it [00:09, 10.78it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train loss: 0.7086908097314363\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "123it [00:11, 10.78it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train loss: 0.7092372676557746\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "143it [00:13, 10.77it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train loss: 0.7096523591812621\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "163it [00:15, 10.78it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train loss: 0.709474505845064\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "183it [00:17, 10.78it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train loss: 0.7096377653970244\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "203it [00:18, 10.78it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train loss: 0.7099583765760583\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "223it [00:20, 10.79it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train loss: 0.7101378788775449\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "225it [00:20, 10.76it/s]\n",
      "100%|█████████████████████████████████████████| 225/225 [00:09<00:00, 24.05it/s]\n",
      "100%|███████████████████████████████████████████| 61/61 [00:02<00:00, 22.88it/s]\n",
      "/mnt/disk2/ndubrovnyi/words_similarity/.venv/lib/python3.8/site-packages/sklearn/neighbors/_nearest_centroid.py:168: UserWarning: Averaging for metrics other than euclidean and manhattan not supported. The average is set to be the mean.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 30\n",
      "Train Loss: 0.7102160636583964\n",
      "ACC@3: 0.9138731304796287\n",
      "feature_extractor.embeddings.word_embeddings.weight False\n",
      "feature_extractor.embeddings.position_embeddings.weight False\n",
      "feature_extractor.embeddings.token_type_embeddings.weight False\n",
      "feature_extractor.embeddings.LayerNorm.weight False\n",
      "feature_extractor.embeddings.LayerNorm.bias False\n",
      "feature_extractor.encoder.layer.0.attention.self.query.weight False\n",
      "feature_extractor.encoder.layer.0.attention.self.query.bias False\n",
      "feature_extractor.encoder.layer.0.attention.self.key.weight False\n",
      "feature_extractor.encoder.layer.0.attention.self.key.bias False\n",
      "feature_extractor.encoder.layer.0.attention.self.value.weight False\n",
      "feature_extractor.encoder.layer.0.attention.self.value.bias False\n",
      "feature_extractor.encoder.layer.0.attention.output.dense.weight False\n",
      "feature_extractor.encoder.layer.0.attention.output.dense.bias False\n",
      "feature_extractor.encoder.layer.0.attention.output.LayerNorm.weight False\n",
      "feature_extractor.encoder.layer.0.attention.output.LayerNorm.bias False\n",
      "feature_extractor.encoder.layer.0.intermediate.dense.weight False\n",
      "feature_extractor.encoder.layer.0.intermediate.dense.bias False\n",
      "feature_extractor.encoder.layer.0.output.dense.weight False\n",
      "feature_extractor.encoder.layer.0.output.dense.bias False\n",
      "feature_extractor.encoder.layer.0.output.LayerNorm.weight False\n",
      "feature_extractor.encoder.layer.0.output.LayerNorm.bias False\n",
      "feature_extractor.encoder.layer.1.attention.self.query.weight False\n",
      "feature_extractor.encoder.layer.1.attention.self.query.bias False\n",
      "feature_extractor.encoder.layer.1.attention.self.key.weight False\n",
      "feature_extractor.encoder.layer.1.attention.self.key.bias False\n",
      "feature_extractor.encoder.layer.1.attention.self.value.weight False\n",
      "feature_extractor.encoder.layer.1.attention.self.value.bias False\n",
      "feature_extractor.encoder.layer.1.attention.output.dense.weight False\n",
      "feature_extractor.encoder.layer.1.attention.output.dense.bias False\n",
      "feature_extractor.encoder.layer.1.attention.output.LayerNorm.weight False\n",
      "feature_extractor.encoder.layer.1.attention.output.LayerNorm.bias False\n",
      "feature_extractor.encoder.layer.1.intermediate.dense.weight False\n",
      "feature_extractor.encoder.layer.1.intermediate.dense.bias False\n",
      "feature_extractor.encoder.layer.1.output.dense.weight False\n",
      "feature_extractor.encoder.layer.1.output.dense.bias False\n",
      "feature_extractor.encoder.layer.1.output.LayerNorm.weight False\n",
      "feature_extractor.encoder.layer.1.output.LayerNorm.bias False\n",
      "feature_extractor.encoder.layer.2.attention.self.query.weight False\n",
      "feature_extractor.encoder.layer.2.attention.self.query.bias False\n",
      "feature_extractor.encoder.layer.2.attention.self.key.weight False\n",
      "feature_extractor.encoder.layer.2.attention.self.key.bias False\n",
      "feature_extractor.encoder.layer.2.attention.self.value.weight False\n",
      "feature_extractor.encoder.layer.2.attention.self.value.bias False\n",
      "feature_extractor.encoder.layer.2.attention.output.dense.weight False\n",
      "feature_extractor.encoder.layer.2.attention.output.dense.bias False\n",
      "feature_extractor.encoder.layer.2.attention.output.LayerNorm.weight False\n",
      "feature_extractor.encoder.layer.2.attention.output.LayerNorm.bias False\n",
      "feature_extractor.encoder.layer.2.intermediate.dense.weight False\n",
      "feature_extractor.encoder.layer.2.intermediate.dense.bias False\n",
      "feature_extractor.encoder.layer.2.output.dense.weight False\n",
      "feature_extractor.encoder.layer.2.output.dense.bias False\n",
      "feature_extractor.encoder.layer.2.output.LayerNorm.weight False\n",
      "feature_extractor.encoder.layer.2.output.LayerNorm.bias False\n",
      "feature_extractor.encoder.layer.3.attention.self.query.weight False\n",
      "feature_extractor.encoder.layer.3.attention.self.query.bias False\n",
      "feature_extractor.encoder.layer.3.attention.self.key.weight False\n",
      "feature_extractor.encoder.layer.3.attention.self.key.bias False\n",
      "feature_extractor.encoder.layer.3.attention.self.value.weight False\n",
      "feature_extractor.encoder.layer.3.attention.self.value.bias False\n",
      "feature_extractor.encoder.layer.3.attention.output.dense.weight False\n",
      "feature_extractor.encoder.layer.3.attention.output.dense.bias False\n",
      "feature_extractor.encoder.layer.3.attention.output.LayerNorm.weight False\n",
      "feature_extractor.encoder.layer.3.attention.output.LayerNorm.bias False\n",
      "feature_extractor.encoder.layer.3.intermediate.dense.weight False\n",
      "feature_extractor.encoder.layer.3.intermediate.dense.bias False\n",
      "feature_extractor.encoder.layer.3.output.dense.weight False\n",
      "feature_extractor.encoder.layer.3.output.dense.bias False\n",
      "feature_extractor.encoder.layer.3.output.LayerNorm.weight False\n",
      "feature_extractor.encoder.layer.3.output.LayerNorm.bias False\n",
      "feature_extractor.encoder.layer.4.attention.self.query.weight True\n",
      "feature_extractor.encoder.layer.4.attention.self.query.bias True\n",
      "feature_extractor.encoder.layer.4.attention.self.key.weight True\n",
      "feature_extractor.encoder.layer.4.attention.self.key.bias True\n",
      "feature_extractor.encoder.layer.4.attention.self.value.weight True\n",
      "feature_extractor.encoder.layer.4.attention.self.value.bias True\n",
      "feature_extractor.encoder.layer.4.attention.output.dense.weight True\n",
      "feature_extractor.encoder.layer.4.attention.output.dense.bias True\n",
      "feature_extractor.encoder.layer.4.attention.output.LayerNorm.weight True\n",
      "feature_extractor.encoder.layer.4.attention.output.LayerNorm.bias True\n",
      "feature_extractor.encoder.layer.4.intermediate.dense.weight True\n",
      "feature_extractor.encoder.layer.4.intermediate.dense.bias True\n",
      "feature_extractor.encoder.layer.4.output.dense.weight True\n",
      "feature_extractor.encoder.layer.4.output.dense.bias True\n",
      "feature_extractor.encoder.layer.4.output.LayerNorm.weight True\n",
      "feature_extractor.encoder.layer.4.output.LayerNorm.bias True\n",
      "feature_extractor.encoder.layer.5.attention.self.query.weight True\n",
      "feature_extractor.encoder.layer.5.attention.self.query.bias True\n",
      "feature_extractor.encoder.layer.5.attention.self.key.weight True\n",
      "feature_extractor.encoder.layer.5.attention.self.key.bias True\n",
      "feature_extractor.encoder.layer.5.attention.self.value.weight True\n",
      "feature_extractor.encoder.layer.5.attention.self.value.bias True\n",
      "feature_extractor.encoder.layer.5.attention.output.dense.weight True\n",
      "feature_extractor.encoder.layer.5.attention.output.dense.bias True\n",
      "feature_extractor.encoder.layer.5.attention.output.LayerNorm.weight True\n",
      "feature_extractor.encoder.layer.5.attention.output.LayerNorm.bias True\n",
      "feature_extractor.encoder.layer.5.intermediate.dense.weight True\n",
      "feature_extractor.encoder.layer.5.intermediate.dense.bias True\n",
      "feature_extractor.encoder.layer.5.output.dense.weight True\n",
      "feature_extractor.encoder.layer.5.output.dense.bias True\n",
      "feature_extractor.encoder.layer.5.output.LayerNorm.weight True\n",
      "feature_extractor.encoder.layer.5.output.LayerNorm.bias True\n",
      "feature_extractor.encoder.layer.6.attention.self.query.weight True\n",
      "feature_extractor.encoder.layer.6.attention.self.query.bias True\n",
      "feature_extractor.encoder.layer.6.attention.self.key.weight True\n",
      "feature_extractor.encoder.layer.6.attention.self.key.bias True\n",
      "feature_extractor.encoder.layer.6.attention.self.value.weight True\n",
      "feature_extractor.encoder.layer.6.attention.self.value.bias True\n",
      "feature_extractor.encoder.layer.6.attention.output.dense.weight True\n",
      "feature_extractor.encoder.layer.6.attention.output.dense.bias True\n",
      "feature_extractor.encoder.layer.6.attention.output.LayerNorm.weight True\n",
      "feature_extractor.encoder.layer.6.attention.output.LayerNorm.bias True\n",
      "feature_extractor.encoder.layer.6.intermediate.dense.weight True\n",
      "feature_extractor.encoder.layer.6.intermediate.dense.bias True\n",
      "feature_extractor.encoder.layer.6.output.dense.weight True\n",
      "feature_extractor.encoder.layer.6.output.dense.bias True\n",
      "feature_extractor.encoder.layer.6.output.LayerNorm.weight True\n",
      "feature_extractor.encoder.layer.6.output.LayerNorm.bias True\n",
      "feature_extractor.encoder.layer.7.attention.self.query.weight True\n",
      "feature_extractor.encoder.layer.7.attention.self.query.bias True\n",
      "feature_extractor.encoder.layer.7.attention.self.key.weight True\n",
      "feature_extractor.encoder.layer.7.attention.self.key.bias True\n",
      "feature_extractor.encoder.layer.7.attention.self.value.weight True\n",
      "feature_extractor.encoder.layer.7.attention.self.value.bias True\n",
      "feature_extractor.encoder.layer.7.attention.output.dense.weight True\n",
      "feature_extractor.encoder.layer.7.attention.output.dense.bias True\n",
      "feature_extractor.encoder.layer.7.attention.output.LayerNorm.weight True\n",
      "feature_extractor.encoder.layer.7.attention.output.LayerNorm.bias True\n",
      "feature_extractor.encoder.layer.7.intermediate.dense.weight True\n",
      "feature_extractor.encoder.layer.7.intermediate.dense.bias True\n",
      "feature_extractor.encoder.layer.7.output.dense.weight True\n",
      "feature_extractor.encoder.layer.7.output.dense.bias True\n",
      "feature_extractor.encoder.layer.7.output.LayerNorm.weight True\n",
      "feature_extractor.encoder.layer.7.output.LayerNorm.bias True\n",
      "feature_extractor.encoder.layer.8.attention.self.query.weight True\n",
      "feature_extractor.encoder.layer.8.attention.self.query.bias True\n",
      "feature_extractor.encoder.layer.8.attention.self.key.weight True\n",
      "feature_extractor.encoder.layer.8.attention.self.key.bias True\n",
      "feature_extractor.encoder.layer.8.attention.self.value.weight True\n",
      "feature_extractor.encoder.layer.8.attention.self.value.bias True\n",
      "feature_extractor.encoder.layer.8.attention.output.dense.weight True\n",
      "feature_extractor.encoder.layer.8.attention.output.dense.bias True\n",
      "feature_extractor.encoder.layer.8.attention.output.LayerNorm.weight True\n",
      "feature_extractor.encoder.layer.8.attention.output.LayerNorm.bias True\n",
      "feature_extractor.encoder.layer.8.intermediate.dense.weight True\n",
      "feature_extractor.encoder.layer.8.intermediate.dense.bias True\n",
      "feature_extractor.encoder.layer.8.output.dense.weight True\n",
      "feature_extractor.encoder.layer.8.output.dense.bias True\n",
      "feature_extractor.encoder.layer.8.output.LayerNorm.weight True\n",
      "feature_extractor.encoder.layer.8.output.LayerNorm.bias True\n",
      "feature_extractor.encoder.layer.9.attention.self.query.weight True\n",
      "feature_extractor.encoder.layer.9.attention.self.query.bias True\n",
      "feature_extractor.encoder.layer.9.attention.self.key.weight True\n",
      "feature_extractor.encoder.layer.9.attention.self.key.bias True\n",
      "feature_extractor.encoder.layer.9.attention.self.value.weight True\n",
      "feature_extractor.encoder.layer.9.attention.self.value.bias True\n",
      "feature_extractor.encoder.layer.9.attention.output.dense.weight True\n",
      "feature_extractor.encoder.layer.9.attention.output.dense.bias True\n",
      "feature_extractor.encoder.layer.9.attention.output.LayerNorm.weight True\n",
      "feature_extractor.encoder.layer.9.attention.output.LayerNorm.bias True\n",
      "feature_extractor.encoder.layer.9.intermediate.dense.weight True\n",
      "feature_extractor.encoder.layer.9.intermediate.dense.bias True\n",
      "feature_extractor.encoder.layer.9.output.dense.weight True\n",
      "feature_extractor.encoder.layer.9.output.dense.bias True\n",
      "feature_extractor.encoder.layer.9.output.LayerNorm.weight True\n",
      "feature_extractor.encoder.layer.9.output.LayerNorm.bias True\n",
      "feature_extractor.encoder.layer.10.attention.self.query.weight True\n",
      "feature_extractor.encoder.layer.10.attention.self.query.bias True\n",
      "feature_extractor.encoder.layer.10.attention.self.key.weight True\n",
      "feature_extractor.encoder.layer.10.attention.self.key.bias True\n",
      "feature_extractor.encoder.layer.10.attention.self.value.weight True\n",
      "feature_extractor.encoder.layer.10.attention.self.value.bias True\n",
      "feature_extractor.encoder.layer.10.attention.output.dense.weight True\n",
      "feature_extractor.encoder.layer.10.attention.output.dense.bias True\n",
      "feature_extractor.encoder.layer.10.attention.output.LayerNorm.weight True\n",
      "feature_extractor.encoder.layer.10.attention.output.LayerNorm.bias True\n",
      "feature_extractor.encoder.layer.10.intermediate.dense.weight True\n",
      "feature_extractor.encoder.layer.10.intermediate.dense.bias True\n",
      "feature_extractor.encoder.layer.10.output.dense.weight True\n",
      "feature_extractor.encoder.layer.10.output.dense.bias True\n",
      "feature_extractor.encoder.layer.10.output.LayerNorm.weight True\n",
      "feature_extractor.encoder.layer.10.output.LayerNorm.bias True\n",
      "feature_extractor.encoder.layer.11.attention.self.query.weight True\n",
      "feature_extractor.encoder.layer.11.attention.self.query.bias True\n",
      "feature_extractor.encoder.layer.11.attention.self.key.weight True\n",
      "feature_extractor.encoder.layer.11.attention.self.key.bias True\n",
      "feature_extractor.encoder.layer.11.attention.self.value.weight True\n",
      "feature_extractor.encoder.layer.11.attention.self.value.bias True\n",
      "feature_extractor.encoder.layer.11.attention.output.dense.weight True\n",
      "feature_extractor.encoder.layer.11.attention.output.dense.bias True\n",
      "feature_extractor.encoder.layer.11.attention.output.LayerNorm.weight True\n",
      "feature_extractor.encoder.layer.11.attention.output.LayerNorm.bias True\n",
      "feature_extractor.encoder.layer.11.intermediate.dense.weight True\n",
      "feature_extractor.encoder.layer.11.intermediate.dense.bias True\n",
      "feature_extractor.encoder.layer.11.output.dense.weight True\n",
      "feature_extractor.encoder.layer.11.output.dense.bias True\n",
      "feature_extractor.encoder.layer.11.output.LayerNorm.weight True\n",
      "feature_extractor.encoder.layer.11.output.LayerNorm.bias True\n",
      "feature_extractor.pooler.dense.weight True\n",
      "feature_extractor.pooler.dense.bias True\n",
      "head.weight True\n",
      "head.bias True\n",
      "arc.W True\n"
     ]
    }
   ],
   "source": [
    "from model import NamesRecognition\n",
    "from utils import fit_epoch, eval_epoch\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "import torch\n",
    "from torch import nn\n",
    "\n",
    "from tqdm import tqdm\n",
    "\n",
    "batch_size = 64\n",
    "num_workers = 4\n",
    "\n",
    "device = 'cuda:3'\n",
    "\n",
    "margin = 0.5\n",
    "scale = 15\n",
    "num_classes = len(set(trainset.labels))\n",
    "feature_extractor_name = 'bert-base-uncased'\n",
    "embedding_size = 512\n",
    "loss_func = 'adacos'\n",
    "\n",
    "other_label = trainset.labels2target['other']\n",
    "\n",
    "num_epochs = 30\n",
    "\n",
    "train_loader = DataLoader(trainset, batch_size=batch_size, shuffle=True, num_workers=num_workers)\n",
    "val_loader = DataLoader(valset, batch_size=batch_size, shuffle=False, num_workers=num_workers)\n",
    "\n",
    "model = NamesRecognition(feature_extractor_name=feature_extractor_name, embedding_size=embedding_size,\n",
    "                        margin=margin, scale=scale, num_of_classes=num_classes, loss_func=loss_func)\n",
    "\n",
    "model.to(device)\n",
    "\n",
    "\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=3e-4)\n",
    "\n",
    "scheduller = torch.optim.lr_scheduler.OneCycleLR(optimizer, max_lr=3e-4, epochs=num_epochs,\n",
    "                                                 steps_per_epoch=len(train_loader), pct_start=0.1)\n",
    "\n",
    "for param in model.parameters():\n",
    "    param.requires_grad = False\n",
    "\n",
    "for param in model.feature_extractor.encoder.layer[11].parameters():\n",
    "    param.requires_grad = False\n",
    "    \n",
    "for param in model.feature_extractor.encoder.layer[10].parameters():\n",
    "    param.requires_grad = False\n",
    "    \n",
    "for param in model.feature_extractor.encoder.layer[9].parameters():\n",
    "    param.requires_grad = False\n",
    "    \n",
    "for param in model.feature_extractor.pooler.parameters():\n",
    "    param.requires_grad = True\n",
    "    \n",
    "for param in model.head.parameters():\n",
    "    param.requires_grad = True\n",
    "    \n",
    "for param in model.arc.parameters():\n",
    "    param.requires_grad = True\n",
    "\n",
    "for name, param in model.named_parameters():\n",
    "    print(name, param.requires_grad)\n",
    "    \n",
    "    \n",
    "\n",
    "\n",
    "version = 'BertAdaCos_v3'\n",
    "    \n",
    "best_acc = 0\n",
    "layer_idx = 11\n",
    "freq = 0\n",
    "for epoch in range(1, num_epochs+1):\n",
    "    \n",
    "    train_loss = fit_epoch(model, train_loader, criterion, optimizer, device, scheduller)\n",
    "    acc = eval_epoch(model, train_loader, val_loader, device, embedding_size, other_label)\n",
    "    \n",
    "    print('Epoch:', epoch)\n",
    "    print('Train Loss:', train_loss)\n",
    "    print('ACC@3:', acc)\n",
    "    \n",
    "    if acc > best_acc:\n",
    "        torch.save(model, f'SaveModels/{version}_{epoch}.pth')\n",
    "        best_acc = acc\n",
    "        if freq >= 4:\n",
    "            for param in model.feature_extractor.encoder.layer[layer_idx].parameters():\n",
    "                param.requires_grad = True\n",
    "            layer_idx -= 1\n",
    "            freq = 0\n",
    "            for name, param in model.named_parameters():\n",
    "                print(name, param.requires_grad)\n",
    "    elif (epoch > 3) and (freq >= 3):\n",
    "        \n",
    "        for param in model.feature_extractor.encoder.layer[layer_idx].parameters():\n",
    "            param.requires_grad = True\n",
    "        layer_idx -= 1\n",
    "        freq = 0\n",
    "        for name, param in model.named_parameters():\n",
    "            print(name, param.requires_grad)\n",
    "        \n",
    "    with open(f'Logs/{version}.txt', 'a') as f:\n",
    "        string = f'Epoch= {epoch} Train loss= {train_loss} ACC@3= {acc}\\n'\n",
    "        f.write(string)\n",
    "        \n",
    "    freq += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f231951",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a3ba806",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
